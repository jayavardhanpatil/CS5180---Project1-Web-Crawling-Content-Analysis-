<?xml version="1.0" encoding="utf-8"?> 
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
 <channel>
  <title>Cloud Blog</title>
  <link>
   https://cloud.google.com/blog/
  </link>
  <description>
   Cloud Blog
  </description>
  <atom:link href="https://cloudblog.withgoogle.com/rss/" rel="self"></atom:link>
  <language>
   en
  </language>
  <lastBuildDate>
   Fri, 25 Sep 2020 18:00:00 -0000
  </lastBuildDate>
  <image>
   <url>
    https://gweb-cloudblog-publish.appspot.com/static/blog/images/google.a51985becaa6.png
   </url>
   <title>Cloud Blog</title>
   <link>
    https://cloud.google.com/blog/
   </link>
  </image>
  <item>
   <title>A decade of evolution by SADA and its customers with Google Maps Platform</title>
   <link>
    https://cloud.google.com/blog/products/maps-platform/decade-evolution-sada-and-its-customers-google-maps-platform/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;Editor’s note:&lt;/b&gt;The growth and adoption of Google Maps Platform over the past 15 years would not have been possible without innovations from our partners and partner ecosystem. We’ve asked a few of our partners to share their reflections on how they were able to embrace geospatial data to not only grow their businesses but also help their customers transform entire industries. Today’s post comes from Edrick Pirveysian, Director of Account Management at SADA Systems. SADA Systems is a Google Cloud Premier Partner with expertise in enterprise consulting, cloud platform migration, custom application development, managed services, user adoption and change management.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Google Maps Platform has been a significant part of &lt;a href="https://sada.com/" target="_blank"&gt;SADA&lt;/a&gt;’s history over the past decade. We launched our maps business in 2013, and we were one of the first partners to go to market with Google Maps Platform. Ever since then, we have been helping our customers build new applications using Google Maps Platform APIs and/or integrate the APIs into their existing applications. These Google Maps Platform-powered applications have allowed our customers to improve operational efficiency, enhance end-user experiences, increase sales, and better visualize data, among many other things. We were proud to be named a Global Winner for Google Cloud Reseller Partner of the Year in 2018 and 2019 due to our excellence in helping customers leverage Google Maps Platform to achieve positive business outcomes.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;As Google Maps Platform recently marked its 15th anniversary milestone, we’d like to highlight a few ways in which our customers rely on SADA’s expertise and solutions built with Google Maps Platform:&lt;/p&gt;&lt;br/&gt;&lt;p&gt;&lt;b&gt;Enhancing the customer experience by shortening time-to-door metrics&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Papa John's App" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/5ce2e8c5021b4c7e5505f443.max-1000x1000.jpeg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Papa John's, a national restaurant brand, tapped us to help them build their customer-facing web and mobile apps with the Places API and Maps JavaScript API. When customers begin their delivery or takeout journey, they are able to leverage the intuitive Autocomplete API for accurate address entry, and then verify that address by displaying a Google map. Once the order is placed, Papa John's internal driver-dispatch application leverages the Geocoding API and Directions API for accurate order processing and delivery scheduling. By using the Directions API, which calculates travel times based on real-time and historic traffic conditions, Papa John's ensures that orders are processed, routed, and delivered in the most optimal way possible. Papa John's is always trying to shorten their 'time-to-door' metrics, and Google Maps Platform is the foundation of this.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;&lt;b&gt;Maximizing sales for efficiency&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Geopointe" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/image_21.max-1000x1000.png"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;One of our customers, Geopointe (formerly Arrowpointe), is one of the top geospatial/mapping applications available on the Salesforce AppExchange. Geopointe uses Google Maps Platform to help salespeople more effectively connect with clients by automatically scheduling trips based on client proximity and optimizing routes based on historic and real-time traffic. Additionally, with Geopointe, salespeople don't have to worry about standardizing client address data; the Geocoding API does it for them. This saves salespeople a lot of time and frustration, especially those that service customers located in rural areas of the U.S. and/or international customers. Geopointe also allows organizations to plan geo-targeted marketing campaigns. Instead of piecing together different zip codes, a sales team can view everything in a specified metro area, add filters, view customer information on a map, and load that data into a marketing campaign.&lt;br/&gt;&lt;/p&gt;&lt;br/&gt;&lt;p&gt;&lt;b&gt;Helping retailers meet consumer expectations during a pandemic&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Today’s consumers are much more sophisticated and demanding than they were even a couple of years ago. For example, when today’s consumers order food, clothes, or other products, they are no longer satisfied with an approximate ETA. Not only do they want more accurate ETAs, but they also expect to be able to track their delivery in real time and see where their driver is on an interactive map.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;On-demand delivery and “buy online pick up in store" shopping (BOPIS) were on the rise before COVID-19, but the pandemic greatly accelerated these two trends. Prior to the pandemic, consumers utilized on-demand delivery and BOPIS out of convenience, but now, these services have almost become necessities as shoppers were unable to spend a lot of time inside of stores. This was a significant shift for many traditional retailers who realized that to survive in today’s environment, they would need to offer more interactive and robust digital shopping experiences. Additionally, retailers need to keep their customers updated on store hour adjustments and policy changes as the nation’s response to COVID-19 continues to evolve.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;As consumer needs dramatically shifted as a result of the pandemic , our team helped several retailers adjust to this “new normal.” I’ve always been impressed with our clients’ ability to keep up with their customers’ expectations, and throughout the pandemic, I’ve been even more impressed. Our customers were forced to reinvent themselves abruptly and on the fly, and Google Maps Platform enabled them to do that.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;&lt;b&gt;Enabling cities to visualize critical infrastructure projects&lt;/b&gt;&lt;/p&gt;&lt;p&gt;In addition to helping our customers develop applications, our company has developed two Google Maps Platform-powered applications, dotMaps and Atom, to help state and municipal governments manage critical infrastructure.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;The &lt;a href="https://www.dotmapsapp.com/" target="_blank"&gt;dotMaps&lt;/a&gt; app was originally built for the Chicago Department of Transportation (CDOT), which needed a way for multiple departments to visualize city projects, and collaborate to resolve conflicts and eliminate duplicative projects. By enabling CDOT to display city infrastructure visually, allowing employees to see and address conflicts at a glance, dotMaps revolutionized the city’s project management and coordination process and saved them over $100M since 2014.&nbsp;&lt;/p&gt;&lt;br/&gt;&lt;p&gt;The app was so successful and revolutionary, we decided to productize it. Now, dotMaps can be used by any organization for effective communication and accurate geolocation for ongoing projects and events, including critical infrastructure (transportation, public works, utility and gas) departments of Transportation (DOTs), as well as private-sector companies, such as construction firms. In its first year leveraging dotMaps, the Seattle Department of Transportation (SDOT) saved $7M from better coordination between projects and agencies.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="dotMAPS" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/dotmaps_1.max-1000x1000.png"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;After developing dotMaps, which manages projects, our team saw a need for an application to manage larger physical assets, such as bridges, streetlights, and road signs, as well as the employees and work tasked with maintaining them. So we developed Atom, which uses Google Maps Platform to let supervisors and dispatchers visualize location data across multiple departments and make real-time decisions on things like scheduling, routing, budget allocation, and asset viability and deterioration.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;&lt;b&gt;Next stop: everywhere!&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Google Maps Platform has a starring role to play in today’s ever-changing business environment. As consumer preferences evolve and technology advances, global logistics will become even more streamlined and automated, and organizations will lean even more heavily on geospatial solutions and mapping services.&nbsp;What will our clients use Google Maps Platform to build next? We can’t wait to find out.&lt;/p&gt;&lt;p&gt;&lt;i&gt;For more information on Google Maps Platform, &lt;a href="https://cloud.google.com/maps-platform/"&gt;visit our website&lt;/a&gt;.&lt;/i&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/maps-platform/how-refresh-local-info-based-user-and-business-needs-local-context/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/2020-09-15_1.max-500x500.png')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;How to refresh local info based on user and business needs with Local Context&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;In June we announced Local Context beta which enables you to quickly and easily embed the familiar Google Maps experience into your deskt...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 25 Sep 2020 18:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/maps-platform/decade-evolution-sada-and-its-customers-google-maps-platform/
   </guid>
   <category>
    Google Maps Platform
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/2020-09-11.max-600x600.png" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>A decade of evolution by SADA and its customers with Google Maps Platform</title>
    <description></description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/2020-09-11.max-600x600.png
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/maps-platform/decade-evolution-sada-and-its-customers-google-maps-platform/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Edrick Pirveysian
    </name>
    <title>Director of Account Management</title>
    <department></department>
    <company>
     SADA Systems
    </company>
   </author>
  </item>
  <item>
   <title>AI Platform Prediction goes GA with improved reliability &amp; ML workflow integration</title>
   <link>
    https://cloud.google.com/blog/products/ai-machine-learning/ai-platform-prediction-better-reliability-ml-workflows/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Machine learning (ML) is transforming businesses and lives alike. Whether it be finding rideshare partners, recommending products or playlists, identifying objects in images, or optimizing marketing campaigns, ML and prediction is at the heart of these experiences. To support&nbsp; businesses like yours that are revolutionizing the world using ML, &lt;a href="https://cloud.google.com/ai-platform"&gt;AI Platform&lt;/a&gt; is committed to providing a world-class, enterprise-ready platform for hosting all of your transformative ML models.&nbsp;&lt;/p&gt;&lt;p&gt;As a part of our continued commitment, we are pleased to announce the general availability of &lt;a href="https://cloud.google.com/ai-platform/prediction/docs"&gt;AI Platform Prediction&lt;/a&gt; based on a &lt;a href="https://cloud.google.com/kubernetes-engine"&gt;Google Kubernetes Engine&lt;/a&gt; (GKE) backend. The new backend architecture is designed for improved reliability, more flexibility via new hardware options (&lt;a href="https://cloud.google.com/ml-engine/docs/machine-types-online-prediction"&gt;Compute Engine machine types&lt;/a&gt; and &lt;a href="https://cloud.google.com/compute/docs/gpus/"&gt;NVIDIA accelerators&lt;/a&gt;), reduced overhead latency, and improved tail latency. In addition to standard features such as autoscaling, access logs, and request/response logging available during our Beta period, we've introduced several updates that improve robustness, flexibility, and usability:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;XGBoost / scikit learn models on high-mem/high-cpu machine types&lt;/b&gt;: Many data scientists like the simplicity and power of XGBoost and scikit learn models for predictions in production. AI Platform makes it simple to deploy models trained using these frameworks with just a few clicks -- we'll handle the complexity of the serving infrastructure on the hardware of your choice.&nbsp;&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Resource Metrics&lt;/b&gt;: An important part of maintaining models in production is understanding their performance characteristics such as GPU, CPU, RAM, and network utilization. These metrics can help make decisions about what hardware to use to minimize latencies and optimize performance. For example, you can view your model's replica count over time to help understand how your autoscaling model responds to changes in traffic and alter minReplicas to optimize cost and/or latency. Resource metrics are now visible for models deployed on GCE machine types from Cloud Console and Stackdriver Metrics.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Regional Endpoints&lt;/b&gt;: We have introduced new endpoints in three regions (us-central1, europe-west4, and asia-east1) with better regional isolation for improved reliability. Models deployed on the regional endpoints stay within the specified region.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;VPC-Service Controls&lt;/b&gt; (Beta): Users can define a security perimeter and deploy Online Prediction models that have access only to resources and services within the perimeter, or within another bridged perimeter. Calls to the CAIP Online Prediction APIs are made from within the perimeter. Private IP will allow VMs and Services within the restricted networks or security perimeters to access the CMLE APIs without having to traverse the public internet.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;But prediction doesn't just stop with serving trained models. Typical ML workflows involve analyzing and understanding models and predictions. Our platform integrates with other important AI technologies to simplify your ML workflows and make you more productive:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/explainable-ai"&gt;&lt;b&gt;Explainable AI&lt;/b&gt;&lt;/a&gt;. To better understand your business, you need to better understand your model. Explainable AI provides information about the predictions from each request and is available exclusively on AI Platform.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-the-what-if-tool-for-cloud-ai-platform-models"&gt;&lt;b&gt;What-if tool&lt;/b&gt;&lt;/a&gt;. Visualize your datasets and better understand the output of your models deployed on the platform.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/ai-platform/prediction/docs/continuous-evaluation"&gt;&lt;b&gt;Continuous Evaluation&lt;/b&gt;&lt;/a&gt;. Obtain metrics about the performance of your live model based on ground-truth labelling of requests sent to your model. Make decisions to retrain or improve the model based on performance over time.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;"[AI Platform Prediction] greatly increases our velocity by providing us with an immediate, managed and robust serving layer for our models and allows us to focus on improving our features and modelling,” said Philippe Adjiman, data scientist tech lead at Waze. Read more about Waze's experience adopting the platform &lt;a href="https://cloud.google.com/blog/products/ai-machine-learning/how-waze-predicts-carpools-using-google-cloud-ai-platform"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;All of these features are available in a fully managed, cluster-less environment with enterprise support -- no need to stand up or manage your own highly available GKE clusters. We also take care of the quota management and protecting your model from overload from clients sending too much traffic. These features of our managed platform allow your data scientists and engineers to focus on business problems instead of managing infrastructure.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/ai-machine-learning/how-waze-predicts-carpools-using-google-cloud-ai-platform/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Automotive_tech.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;How Waze predicts carpools with Google Cloud’s AI Platform&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;How Waze predicts carpools using Google Cloud AI Platform.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 25 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/ai-machine-learning/ai-platform-prediction-better-reliability-ml-workflows/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    AI &amp; Machine Learning
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_AI_Platform.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>AI Platform Prediction goes GA with improved reliability &amp; ML workflow integration</title>
    <description>
     AI Platform Prediction goes GA with enhanced reliability &amp; ML workflow integration.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_AI_Platform.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/ai-machine-learning/ai-platform-prediction-better-reliability-ml-workflows/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Robbie Haertel
    </name>
    <title>Staff Engineer</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Bhupesh Chandra
    </name>
    <title>Senior Engineer</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>How Waze predicts carpools with Google Cloud’s AI Platform</title>
   <link>
    https://cloud.google.com/blog/products/ai-machine-learning/how-waze-predicts-carpools-using-google-cloud-ai-platform/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Waze’s mission is to eliminate traffic and we believe our carpool feature is a cornerstone that will help us achieve it. In our carpool apps, a rider (or a driver) is presented with a list of users that are relevant for their commute (see below). From there, the rider or the driver can initiate an offer to carpool, and if the other side accepts it, it’s a match and a carpool is born.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="wazecarpool.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/wazecarpool.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Let’s consider a rider who is commuting from somewhere in Tel-Aviv to Google’s offices, as an example that we’ll use throughout this post. Our goal will be to present to that rider a list of drivers that are geographically relevant to her commute, and to rank that list by the highest likelihood of the carpool between that rider and any driver on the list to actually happen.&nbsp;&lt;/p&gt;&lt;p&gt;Finding all the relevant candidates in a few seconds involves a lot of engineering and algorithmic challenges, and we’ve dedicated a full team of talented engineers to&nbsp;the task. In this post we’ll focus on the machine learning part of the system responsible for ranking those candidates.&nbsp;&lt;/p&gt;&lt;p&gt;In particular:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;If hundreds (or more) drivers could be a good match for our rider (in our example), how can we build a ML model that would decide which ones to show her first?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;How can we build the system in a way that allows us to iterate quickly on complex models in production while guaranteeing a low latency online in order to keep the overall user experience fast and delightful?&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;ML models to rank lists of drivers and riders&lt;/h3&gt;&lt;p&gt;So, the rider in our example sees a list of potential drivers. For each such driver, we need to answer two questions:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;What is the probability that our rider will send this driver a request to carpool?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;What is the probability that the driver will actually accept the rider’s request?&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;We solve this using machine learning: we build models that estimate those two probabilities based on aggregated historical data of drivers and riders sending and accepting requests to carpool. We use the models to sort drivers from highest to lowest likelihood of the carpool to actually happen.&lt;/p&gt;&lt;p&gt;The models we’re using combine close to 90 signals to estimate those probabilities. Below are a few of the most important signals to our models:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph_with_image"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;figure class="article-image--wrap-small "&gt;&lt;img alt="Star Ratings.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Star_Ratings.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Star Ratings&lt;/b&gt;: higher rated drivers tend to get more requests&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Walking distance from pickup and dropoff&lt;/b&gt;: riders want to start and end their rides as close as possible to the driver’s route. But, the total walking distance (as seen in the screenshot above) isn’t everything: riders also care about how the walking distance compares to their overall commute length. Consider the two plans below of two different riders: both have 15 minutes walking, but the second one looks much more acceptable given that the commute length is larger to start with, while in the first one, the rider needs to walk as much as the actual carpool length, and is thus much less likely to be interested. The signal that is capturing this in the model and that came up as one of the most important signals, is the ratio between the walking and carpool distance.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Walking distance from pickup and dropoff.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Walking_distance_from_pic.1032064714671295.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;The same kind of consideration is valid on the driver side, when considering the length of the detour compared to the driver’s full drive from origin to destination.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph_with_image"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;figure class="article-image--wrap-small "&gt;&lt;img alt="Driver’s intent.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Drivers_intent.0217009504240190.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Driver’s intent&lt;/b&gt;:&nbsp;One of the most important factors impacting the probability of a driver to accept a request to carpool (sent by a rider) is her intent to actually carpool. We have several signals indicating a driver's intent, but the one that came up as the most important (as captured by the model) is the last time the driver was seen in the app. The more recent it is, the more likely the driver is to accept a request to carpool sent by a rider.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Model vs. Serving complexity&lt;/h3&gt;&lt;p&gt;In the early stage of our product, we started with simple logistic regression models to estimate the likelihood of users sending/accepting offers. The models were trained offline using &lt;a href="https://scikit-learn.org/" target="_blank"&gt;scikit learn&lt;/a&gt;. The training set was obtained using a “log and learn” approach (logging signals exactly as they were during serving time) over ~90 different signals, and the learned weights were injected into our serving layer.&nbsp;&lt;/p&gt;&lt;p&gt;Although those models were doing a pretty good job, we observed via offline experiments the great potential of more advanced non linear models such as &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" target="_blank"&gt;gradient boosted regression classifiers&lt;/a&gt; for our ranking task.&nbsp;&lt;/p&gt;&lt;p&gt;Implementing an in-memory fast serving layer supporting such advanced models would require non-trivial effort, as well as an on-going maintenance cost. A much simpler option was to delegate the serving layer to an external managed service that can be called via a REST API. However, we needed to be sure that it wouldn’t add too much latency to the overall flow.&nbsp;&lt;/p&gt;&lt;p&gt;In order to make our decision, we decided to do a quick POC using the &lt;a href="https://cloud.google.com/ai-platform/prediction/docs/overview"&gt;AI Platform Online Prediction&lt;/a&gt; service, which sounded like a potential great fit for our needs at the serving layer.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;A quick (and successful) POC&lt;/h3&gt;&lt;p&gt;We trained our gradient boosted models over our ~90 signals using scikit learn, serialized it as a pickle file, and simply &lt;a href="https://cloud.google.com/ai-platform/prediction/docs/deploying-models"&gt;deployed&lt;/a&gt; it as-is to the Google Cloud &lt;a href="https://cloud.google.com/ai-platform"&gt;AI Platform&lt;/a&gt;. Done. We get a fully managed serving layer for our advanced model through a REST API. From there, we just had to connect it to our java serving layer (a lot of important details to make it work, but unrelated to the pure model serving layer).&nbsp;&lt;/p&gt;&lt;p&gt;Below is a very high level schema of what our offline/online training/serving architecture looks like. The carpool serving layer is responsible for a lot of logic around computing/fetching the relevant candidates to score, but we focus here on the pure ranking ML part. Google Cloud AI Platform plays a key role in that architecture. It greatly increases our velocity by providing us with an immediate, managed and robust serving layer for our models and allows us to focus on improving our features and modelling.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/serving_vs_training.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="serving vs training.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/serving_vs_training.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Click to enlarge&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Increased velocity and the peace of mind to focus on our core model logic was great, but a core constraint was around the latency added by an external REST API call at the serving layer. We performed various latency checks/load tests against the online prediction API for different models and input sizes. AI Platform provided the low double digit millisecond latency that was necessary for our application.&nbsp;&lt;/p&gt;&lt;p&gt;In just a couple of weeks, we were able to implement and connect the components together and deploy the model in production for AB testing. Even though our previous models (a set of logistic regression classifiers) were performing well, we were thrilled to observe significant improvements on our core KPIs in the AB test. But what mattered even more for us, was having a platform to iterate quickly over even more complex models, without having to deal with the training/serving implementation and deployment headaches.&nbsp;&lt;/p&gt;&lt;h3&gt;The tip of the (Google Cloud AI Platform) iceberg&lt;/h3&gt;&lt;p&gt;In the future we plan to explore more sophisticated models using Tensorflow, along with Google Cloud’s &lt;a href="https://cloud.google.com/explainable-ai"&gt;Explainable AI&lt;/a&gt; component that will simplify the development of these sophisticated models by providing deeper insights into how they are performing. AI Platform Prediction’s recent &lt;a href="https://cloud.google.com/blog/products/ai-machine-learning/ai-platform-prediction-better-reliability-ml-workflows"&gt;GA release&lt;/a&gt; of support for GPUs and multiple high-memory and high-compute instance types will make it easy for us to deploy more sophisticated models in a cost effective way.&lt;/p&gt;&lt;p&gt;Based on our early success with the AI Platform Prediction service, we plan to aggressively leverage other compelling components offered by GCP’s &lt;a href="https://cloud.google.com/ai-platform"&gt;AI Platform&lt;/a&gt;, such as the Training service w/ &lt;a href="https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning"&gt;hyper parameter tuning&lt;/a&gt;, &lt;a href="https://cloud.google.com/ai-platform/pipelines/docs"&gt;Pipelines&lt;/a&gt;, etc. In fact, multiple data science teams and projects (ads, future drive predictions, ETA modelling) at Waze are already using or started exploring other existing (or upcoming) components of the AI Platform. More on that in future posts.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/ai-machine-learning/ai-platform-prediction-better-reliability-ml-workflows/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_AI_Platform.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;AI Platform Prediction goes GA with improved reliability &amp;amp; ML workflow integration&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;AI Platform Prediction goes GA with enhanced reliability &amp;amp; ML workflow integration.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 25 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/ai-machine-learning/how-waze-predicts-carpools-using-google-cloud-ai-platform/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    AI &amp; Machine Learning
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Automotive_tech.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>How Waze predicts carpools with Google Cloud’s AI Platform</title>
    <description>
     How Waze predicts carpools using Google Cloud AI Platform.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Automotive_tech.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/ai-machine-learning/how-waze-predicts-carpools-using-google-cloud-ai-platform/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Philippe Adjiman
    </name>
    <title>Senior Data Scientist, Waze</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Better monitoring and logging for Compute Engine VMs</title>
   <link>
    https://cloud.google.com/blog/products/management-tools/compute-engine-gets-better-monitoring-and-logging/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Over the past several months we’ve been focused on improving observability and operations workflows for &lt;a href="https://cloud.google.com/compute"&gt;Compute Engine&lt;/a&gt;. Today, we are excited to share the first wave of these enhancements are now available. These include:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Significantly improved operating system support for the Cloud Monitoring and Cloud Logging agents.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The ability to rapidly deploy, update, and remove agents to groups of VMs, or all of your VMs, by policy, with as little as a single gcloud command.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;New VM-specific features within the Cloud Monitoring console, which we’ll discuss in an upcoming blog post.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Understanding agents&lt;/h2&gt;&lt;p&gt;Agents remain a key way to get fine-grained visibility into a virtual machine’s host operating system, and applications running on Compute Engine are no different.&nbsp;&lt;/p&gt;&lt;p&gt;Out of the box, every Compute Engine instance (or managed instance group) provides some level of telemetry, including metrics for CPU utilization, uptime, disk throughput and operations, and networking operations. To capture more advanced operating system metrics like memory consumption and disk utilization, metrics from commonly used applications (databases, web proxies, etc.), and logs from your applications, you need to install the Cloud Monitoring and Cloud Logging agents onto each VM.&lt;/p&gt;&lt;h3&gt;Automatic agent installation and management&lt;/h3&gt;&lt;p&gt;Because agents are so essential in VM environments, we’ve&lt;a href="https://cloud.google.com/stackdriver/docs/solutions/managing-agent-policies"&gt;automated the process of installing, updating, and removing the Cloud Monitoring Logging agents&lt;/a&gt; onto groups of Compute Engine VMs, or your entire fleet, via a new set of gcloud commands. With as little as one command, you can create a policy that governs existing and new VMs, ensuring proper installation and optional auto-upgrade of both agents. This is a great way to start using Cloud Monitoring or Cloud Logging right away, and to scale metrics and logs collection from a single VM to all VMs in a project.&lt;/p&gt;&lt;p&gt;These policies can be applied to Linux virtual machines now as a part of the public alpha and will apply to Windows VMs soon.&lt;/p&gt;&lt;h3&gt;Improved operating system support&lt;/h3&gt;&lt;p&gt;Over the past year, we’ve added Cloud Monitoring and Logging agent support to a host of new operating systems.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/monitoring/agent#supported_operating_systems"&gt;The Monitoring and Logging agents are now compatible with 30 of Compute Engine’s available Linux images&lt;/a&gt;, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;CentOS 7+&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Red Hat Enterprise Linux 7+&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Debian 9+&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SUSE Linux Enterprise Server 12+&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ubuntu 16+&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;With these additions, the Cloud Monitoring Linux agents can be used on every Compute Engine host operating system other than the Container Optimized OS, which has &lt;a href="https://cloud.google.com/container-optimized-os/docs/how-to/monitoring"&gt;monitoring and logging capabilities built in to the OS itself&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Cloud Monitoring has been able to capture system and SQL Server metrics for Windows virtual machines since before 2015, thanks to its &lt;a href="https://cloud.google.com/monitoring/agent#windows_operating_systems"&gt;Windows agent&lt;/a&gt;. We’re currently improving the compatibility, quality, and functionality of our Windows support with a new agent that provides the following enhancements:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Capturing the same advanced OS metrics as the Cloud Monitoring Linux agent, rather than a smaller incompatible set&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Compatibility with more Windows versions&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Capturing application metrics from IIS, SQL Server, and Windows performance counters&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The new agent is in preview. Please contact your account manager if you would like to participate in early tests.&lt;/p&gt;&lt;h2&gt;Wrapping up&lt;/h2&gt;&lt;p&gt;We hope you enjoy these improvements to Cloud Monitoring and Cloud Logging, and we look forward to bringing even more capabilities to the platform. To check out these new features, go to &lt;a href="https://cloud.google.com/stackdriver/docs/solutions/managing-agent-policies"&gt;our documentation for these new features&lt;/a&gt; or to the Cloud Monitoring and Logging in the &lt;a href="https://console.cloud.google.com/"&gt;Google Cloud Console&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/management-tools/cloud-monitoring-gets-fleet-wide-vm-monitoring/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/BlogHeader_Data_Management_1.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;All together now: Fleet-wide monitoring for your Compute Engine VMs&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Cloud Monitoring now lets you manage an entire fleet of Compute Engine VMs.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 25 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/management-tools/compute-engine-gets-better-monitoring-and-logging/
   </guid>
   <category>
    Compute
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Management Tools
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Compute_workload_pmsK0uM.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Better monitoring and logging for Compute Engine VMs</title>
    <description>
     New features in Cloud Monitoring and Cloud Logging simplify operations of your Compute Engine instances.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Compute_workload_pmsK0uM.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/management-tools/compute-engine-gets-better-monitoring-and-logging/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Morgan McLean
    </name>
    <title>Product Manager</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Introducing Student Success Services from Google Cloud</title>
   <link>
    https://cloud.google.com/blog/topics/education/introducing-student-success-services-from-google-cloud/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;The shift to remote learning at all levels of education has thrown the challenges of ensuring student success and the student experience into sharp focus. Educational institutions want to guide students throughout their academic careers and improve graduation rates. Students want better remote learning options and ways to collaborate with peers and seek advice from instructors. There is a wealth of data that could drive decisions about these needs, but it’s often locked away in legacy technologies.&nbsp;&lt;/p&gt;&lt;p&gt;We have launched Google Cloud’s Student Success Services to help meet these challenges. Student Success Services is a set of tools that aims to unlock student successes with personalized assistants, real-time insights, collaboration tools and more for higher ed and K-12 learners. Using built-in artificial intelligence (AI) models and analytics to gather data and use it for decision-making, this bundle of services benefits both institutions and students by engaging students, improving remote and in-person learning, and creating a modern, fulfilling student experience.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-video"&gt;&lt;div class="article-module article-video "&gt;&lt;figure&gt;&lt;a class="h-c-video h-c-video--marquee" data-glue-modal-disabled-on-mobile="true" data-glue-modal-trigger="uni-modal-hZLBcHYrIU4-" href="https://youtube.com/watch?v=hZLBcHYrIU4"&gt;&lt;img alt="Student success is about much more than getting good grades. It also includes giving advisors more time to coach their students, helping students monitor and improve their progress on their own, and running processes like class registration more efficiently. Google Cloud is working with higher education institutions to help meet these challenges, and more. In this video, we’ll look at some ways Brown University, Strayer University and Penn State World Campus are using our AI tools and other technology to support more students, more effectively—allowing them to take charge of their success." src="//img.youtube.com/vi/hZLBcHYrIU4/maxresdefault.jpg"/&gt;&lt;svg class="h-c-video__play h-c-icon h-c-icon--color-white" role="img"&gt;&lt;use xlink:href="#mi-youtube-icon"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="h-c-modal--video" data-glue-modal="uni-modal-hZLBcHYrIU4-" data-glue-modal-close-label="Close Dialog"&gt;&lt;a class="glue-yt-video" data-glue-yt-video-autoplay="true" data-glue-yt-video-height="99%" data-glue-yt-video-vid="hZLBcHYrIU4" data-glue-yt-video-width="100%" href="https://youtube.com/watch?v=hZLBcHYrIU4" ng-cloak=""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;How to improve the student experience&lt;/h3&gt;&lt;p&gt;Google Cloud’s Student Success Services includes the following services that help institutions understand student needs and quickly respond with solutions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Virtual assistants for round-the-clock support&lt;/b&gt;: Use virtual assistants, created with Google’s machine learning and natural language tools, to support students 24/7 with instant answers. The virtual assistants can be trained to respond instantly to questions on topics like enrollment status and registration deadlines, freeing up staff for more personal student guidance.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Tutors for personalized learning&lt;/b&gt;: Give students access to skills practice and guidance from intelligent technology tools. Our APIs and AI-powered learning tools can guide students in their writing practice or coaching for reading comprehension.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Smart analytics to improve student engagement, achievement, and retention&lt;/b&gt;:&nbsp;The &lt;a href="https://unizin.org/" target="_blank"&gt;Unizin Data Platform&lt;/a&gt;, built on Google Cloud, is an institution-level data platform that aggregates, cleans, models, and stores all teaching and learning data to create a holistic view of the student. Too often, advisors and educators don’t have the information on the students they support until it’s too late to intervene. Google’s Student Success Services allow organizations to easily and securely share aggregate data and enables them to see a unified portrait of learners, uncover insights across diverse student groups at every level, and intervene in real time.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Scalable student learning&lt;/b&gt;: Distance shouldn’t be a barrier to student success. Google Meet allows groups of up to 250 people to talk face-to-face for classroom learning as well as employee meetings, in compliance with regulations such as HIPAA and FERPA. With Meet’s premium features, meeting leaders can add closed-captioning and recording, while sharing meetings via learning management systems. For schools that rely on live streams, Meet can accommodate up to 100,000 viewers. And with virtual desktop infrastructure (VDI) remote learning solutions for distance learners, educators can create virtual labs and access compute power remotely.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Incidence and intelligence management&lt;/b&gt;: Get real-time insights to detect issues and rapidly respond to risks on and off campus, as well as track student and campus health.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;“We believe that a data-informed academic mission must play an essential role in helping every student reach their potential. Every week, we see our institutions leveraging the Unizin Data Platform to engage, enrich, and empower their students with data, analytics, and insights” says Etienne Pelaprat, Chief Technology Officer of Unizin.&lt;/p&gt;&lt;p&gt;Creating an equitable playing field for student success is also a goal of the University of Lynchburg in Virginia. “We have students learning with us from all over the world, especially in our online graduate programs,” says Charley Butcher, the university’s director of instructional technology. Those students can join classes using Meet and a web browser from anywhere they happen to be—a benefit at any time, but especially now when remote classes are often the only option for students. And it’s not just graduate students: During the pandemic-related campus shutdown, Meet is helping all students work closely with their instructors.&lt;/p&gt;&lt;p&gt;The need to lift student success is certainly critical right now—but when the pandemic recedes, educators will likely still be adjusting to very different learning environments for their students. “In this year of disruption, we’ve seen just how much technology can impact the student experience. As teaching and learning become more digital, institutions must prioritize innovation and technology. This should go beyond learning platforms and include capabilities like artificial intelligence and predictive analytics – supports that students increasingly expect as part of their experience and are proven to be successful says Joe Schaefer, Chief Transformation Officer at Strategic Education.&nbsp;&lt;/p&gt;&lt;p&gt;That’s why attention to student success is critical. If you’re looking for more guidance, join us for Student Success Week [register for free at: &lt;a href="http://g.co/cloud/student-success-week" target="_blank"&gt;g.co/cloud/student-success-week&lt;/a&gt;], or reach out to our team to get started.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/topics/education/improving-student-success-with-data-analytics-and-virtual-assistants/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Training.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Campuses use data analytics and virtual agents for student success&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Student success is about much more than getting good grades. It also includes giving instructors more time to coach their students, helpi...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 25 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/topics/education/introducing-student-success-services-from-google-cloud/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Education
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/560-GCP-Higher-Ed-Hero_eiTbZy8.max-600x600.png" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Introducing Student Success Services from Google Cloud</title>
    <description>
     Student Success Services is a set of tools/services that aims to unlock student successes with personalized assistants, real-time insights, collaboration tools and more for higher ed and K-12 learners.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/560-GCP-Higher-Ed-Hero_eiTbZy8.max-600x600.png
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/topics/education/introducing-student-success-services-from-google-cloud/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Mike Daniels
    </name>
    <title>Vice President, Global Public Sector, Google Cloud</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>All together now: Fleet-wide monitoring for your Compute Engine VMs</title>
   <link>
    https://cloud.google.com/blog/products/management-tools/cloud-monitoring-gets-fleet-wide-vm-monitoring/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Cloud Monitoring has always provided comprehensive visibility and management into individual Compute Engine virtual machines (VMs). But many Google Cloud customers have hundreds, thousands, or tens of thousands of VMs that they need to manage. Cloud Monitoring now gives you zero-config, out-of-the-box visibility into your entire Compute Engine VM fleet, with quick access to advanced Monitoring features such as installing the Cloud Monitoring agent and configuring fleetwide alerts. Our new &lt;a href="https://console.cloud.google.com/monitoring/dashboards/summary/infrastructure"&gt;Infrastructure Summary dashboard&lt;/a&gt; and expanded VM Instances dashboard jump-start your troubleshooting with no setup required!&lt;/p&gt;&lt;h3&gt;Monitor your VM fleet’s health with infrastructure summary&lt;/h3&gt;&lt;p&gt;The new single-pane-of-glass &lt;a href="https://console.cloud.google.com/monitoring/dashboards/summary/infrastructure"&gt;Infrastructure Summary dashboard&lt;/a&gt; lets you see aggregate fleet-wide statistics at a glance, and provides insight into the top VMs for a select group of key CPU, disk, memory, and network metrics. You can use the quick links in the top left to jump into detailed troubleshooting dashboards for load balancers, network, and VM instances. The filter bar enables you to narrow your view if you want to see a specific subset of VMs.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="1 infrastructure summary.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/1_infrastructure_summary.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Troubleshoot issues with VM instances fleet-wide view&lt;/h3&gt;&lt;p&gt;You’ve always been able to view and filter all your VM instances in Cloud Monitoring, and now you can do much more. The &lt;a href="http://console.cloud.google.com/monitoring/dashboards/resourceList/gce_instance"&gt;VM Instances dashboard&lt;/a&gt; now includes agent visibility and installation, and its new tabs let you see fleet-wide information across key metrics.&lt;/p&gt;&lt;p&gt;View top VMs across key metrics for CPU, disk, memory, and network&lt;/p&gt;&lt;p&gt;Dedicated tabs for CPU, disk, memory, and network show you outlier VMs for key metrics in each category, so you can visually inspect for anomalies and quickly drill into problem areas and VMs. Filtering allows you to narrow down the set of VMs being displayed in any tab for detailed analysis.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="2 View top VMs across key metrics for CPU.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_View_top_VMs_across_key_metrics_for_CPU.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;View Monitoring agent status and install in the UI&lt;/h3&gt;&lt;p&gt;The per-VM status of the &lt;a href="http://console.cloud.google.com/monitoring/dashboards/resourceList/gce_instance?defaultToExplore=true"&gt;Cloud Monitoring agent&lt;/a&gt; is now available in the main inventory page, and you can install the agent on a VM using our built-in wizard. Use the agent to track specified system and application metrics, including:&nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Memory and disk metrics&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Advanced system metrics&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Metrics for workloads like MySQL, Apache, Java virtual machine, and others&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you want to install and manage the agent across multiple VMs at once, you can use our new &lt;a href="https://cloud.google.com/stackdriver/docs/solutions/managing-agent-policies"&gt;Ops Agent Policies&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="3 View Monitoring agent status.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/3_View_Monitoring_agent_status.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Understand your advanced metrics&lt;/h3&gt;&lt;p&gt;The “Explore” tab gives you insight into the advanced metrics you’re currently collecting in Cloud Monitoring, and quick links to information on how to send additional metrics, so you can see even more metrics in one place.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="4 Understand your advanced metrics.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Understand_your_advanced_metrics.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Enable recommended alerts&lt;/h3&gt;&lt;p&gt;We’ve made it easy to enable predefined recommended alerts across your whole VM fleet. With one click, you can ensure that all the VMs in your fleet are continuously monitored for excessive utilization (memory, disk, network, etc), and receive alert notifications across a variety of channels (email, SMS, Slack, PagerDuty, Cloud Console mobile app, Cloud Pub/Sub, and webhooks). You can also override recommended alert thresholds based on your needs.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="5 Enable recommended alerts.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Enable_recommended_alerts.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;A fleet of new capabilities&lt;/h3&gt;&lt;p&gt;As with all our operations tools, we want Cloud Monitoring to include everything you need to manage your environment, whether it consists of one VM or thousands. To get started with Cloud Monitoring, check out this &lt;a href="https://github.com/GoogleCloudPlatform/cloud-ops-sandbox" target="_blank"&gt;demo&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/management-tools/compute-engine-gets-better-monitoring-and-logging/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Compute_workload_pmsK0uM.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Better monitoring and logging for Compute Engine VMs&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;New features in Cloud Monitoring and Cloud Logging simplify operations of your Compute Engine instances.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 24 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/management-tools/cloud-monitoring-gets-fleet-wide-vm-monitoring/
   </guid>
   <category>
    Compute
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Management Tools
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/BlogHeader_Data_Management_1.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>All together now: Fleet-wide monitoring for your Compute Engine VMs</title>
    <description>
     Cloud Monitoring now lets you manage an entire fleet of Compute Engine VMs.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/BlogHeader_Data_Management_1.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/management-tools/cloud-monitoring-gets-fleet-wide-vm-monitoring/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Marie Cosgrove-Davies
    </name>
    <title>Product Manager, Google Cloud</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Anthos in depth: Easy load balancing for your on-prem workloads</title>
   <link>
    https://cloud.google.com/blog/topics/hybrid-cloud/deep-dive-into-anthos-bundled-load-balancer/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;For organizations that need to run their workloads on-prem, Anthos is a real game changer. As a hybrid multi-cloud platform that’s managed by Google Cloud, Anthos includes all the innovations that we’ve developed for Google Kubernetes Engine (GKE) over the years, but running in the customer’s data center. And as such, Anthos can integrate with your existing on-prem networking stack.&nbsp;&lt;/p&gt;&lt;p&gt;One of the key pieces of integration is getting traffic into the Anthos cluster, which often involves using an external load balancer. When running Anthos on Google Cloud, you create a Kubernetes service accessible from the internet through Ingress or servicetype load balancer, and Google Cloud takes care of assigning the virtual IP (VIP) and making it available to the rest of the world. In contrast, when running Anthos on-prem, advertising the service’s VIP to your on-prem network happens using an external load balancer.&nbsp;&lt;/p&gt;&lt;p&gt;Anthos provides three different options for deploying an external load balancer: the F5 Container Ingress Services (CIS) controller; manually mapping your load balancer to Kubernetes with static mapping; and Anthos’ own bundled load balancer.&lt;/p&gt;&lt;p&gt;In this post, we’ll introduce these three options and dive deep into the Anthos bundled load balancer.&lt;/p&gt;&lt;p&gt;&lt;b&gt;F5 load balancing&lt;/b&gt;&lt;/p&gt;&lt;p&gt;In this mode, Anthos &lt;a href="https://cloud.google.com/solutions/partners/installing-f5-big-ip-adc-for-gke-on-prem"&gt;integrates&lt;/a&gt; with F5 by including the F5 Container Ingress Services (CIS) controller with Anthos running on-prem. This approach is ideal if you have an existing investment in F5 load balancing and want to use it with your Anthos on-prem cluster.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Manual load balancing&lt;/b&gt;&lt;/p&gt;&lt;p&gt;If you have another third-party load balancer, you can manually map your external load balancer to your Kubernetes resources, allowing you to use the load balancer of your choice. As there is no controller here to map the Kubernetes resources to the external load balancer, you need to perform static mapping of the load balancer service.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Anthos-bundled load balancing&lt;/b&gt;&lt;/p&gt;&lt;p&gt;In both the above modes, there are costs (licensing and hardware) and expertise associated with managing the external load balancer. More importantly, there can be organizational friction, both technical and non-technical, as external load balancers and Anthos clusters are often managed by different teams. Anthos’ bundled load balancer provides an option to customers who want to program the VIP dynamically, without having to configure or support a third-party option.&lt;/p&gt;&lt;p&gt;The Anthos-bundled load balancer takes care of integrating external load balancer functionality as well as announcing the VIP to the external world. In contrast to the previous modes, Anthos itself now bridges the Kubernetes domain with the rest of your network. This approach brings several advantages:&nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The team managing the on-prem Anthos cluster also manages the advertisement of VIPs. This mitigates the requirements for any tight collaboration and dependency between different organizations, groups and admins.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Costs are streamlined, as you don’t have to manage a separate invoice, bill or vendor for your external load balancing needs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Simplified management, as Anthos controls both the controller as well as the VIP announcement. This has benefits in operational management, support, provisioning etc., making it a more seamless experience.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Multinational investment banking firm HSBC uses Anthos’ bundled load balancer and reports that it’s easy to install and configure, with minimal system requirements.&nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“Anthos running on-premises has brought the best of Google’s managed Kubernetes to our data centers. Specifically, the bundled load-balancer provides HSBC with a highly available, high performing, layer 4 load-balancer with minimal system requirements. Configuration and installation are simple and automate deployment for each new on-prem cluster. This decreases our time to market, installation complexity, and costs for each cluster we deploy.”&lt;/i&gt; - Scott Surovich Global Container Engineering Lead - HSBC Operations, Services &amp;amp; Technology&lt;/p&gt;&lt;h3&gt;Using the Anthos bundled load balancer&nbsp;&lt;/h3&gt;&lt;p&gt;Using Anthos’ bundled load balancer on-prem is a relatively straightforward process.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="bundle load balancer.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/bundle_load_balancer.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;The bundled load balancer uses the &lt;a href="https://github.com/google/seesaw" target="_blank"&gt;Seesaw load balancer&lt;/a&gt;, which Google created and open sourced. In high availability mode, two instances run in active-passive pairs talking the standard &lt;a href="https://en.wikipedia.org/wiki/Virtual_Router_Redundancy_Protocol" target="_blank"&gt;Virtual Router Redundancy Protocol (VRRP)&lt;/a&gt;. The passive instance becomes the active if it does not receive an advertisement from the active instance for two seconds, based on today’s default configuration.&lt;/p&gt;&lt;p&gt;You can create a load-balancer-typed Kubernetes service to expose your application through the bundled load balancer. For example:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Here, the bundled load balancer exposes a service to clients at port 80. The service config is sent to the load balancer automatically, which begins to announce SVIP by replying to &lt;a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol" target="_blank"&gt;ARP&lt;/a&gt; (address resolution protocol) requests. The load balancer runs in &lt;a href="https://en.wikipedia.org/wiki/IP_Virtual_Server" target="_blank"&gt;IPVS&lt;/a&gt; gatewaying mode (also known as “direct routing” mode), not touching the IP layer of packets and delivering packets to a Kubernetes node by modifying the destination MAC address. The advantage of running in this mode is that it doesn’t add any additional IP headers to the traffic, and therefore does not impact performance. The Kubernetes data plane (iptables in this case) on the node then picks up the packets destined to SVIP:80 and routes them to backends pods. Thanks to the gatewaying mode, the load balancer achieves “Direct Server Return (DSR)” and the responses bypass the load balancers. This saves capacity needed for the load balancers. Also because of DSR, the client IP can be visible in pods by setting “externalTrafficPolicy” to “Local” on the service.&lt;/p&gt;&lt;h3&gt;No external load balancer? No problem&lt;/h3&gt;&lt;p&gt;If you don’t have an external load balancer that’s qualified for your network—or don’t have the in-house expertise to set one up—Anthos’ bundled load balancer can help. And thankfully, it’s easy to set up and use. Click here to learn more about &lt;a href="https://cloud.google.com/anthos/gke/docs/on-prem/concepts/networking"&gt;Anthos’ networking capabilities&lt;/a&gt;, and stay tuned for our upcoming post, where we’ll show you how to use GKE private clusters for increased security and compliance.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/exposing-services-on-gke/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Containers_Uy53clo.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;GKE best practices: Exposing GKE applications through Ingress and Services&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;We'll walk through the different factors you should consider when exposing applications on GKE, explain how they impact application expos...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 24 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/topics/hybrid-cloud/deep-dive-into-anthos-bundled-load-balancer/
   </guid>
   <category>
    Networking
   </category>
   <category>
    Containers &amp; Kubernetes
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Anthos
   </category>
   <category>
    Hybrid Cloud
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Anthos_A_pmqIcQ2.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Anthos in depth: Easy load balancing for your on-prem workloads</title>
    <description>
     Your Anthos subscription includes an external load balancer that can help you connect data to your on-prem Anthos cluster.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Anthos_A_pmqIcQ2.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/topics/hybrid-cloud/deep-dive-into-anthos-bundled-load-balancer/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Mahesh Narayanan
    </name>
    <title>Product Manager, GKE</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Yuan Liu
    </name>
    <title>Software Engineer, GKE</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Migrate your custom ML models to Google Cloud in 3 steps</title>
   <link>
    https://cloud.google.com/blog/products/ai-machine-learning/migrate-your-custom-ml-models-to-google-cloud-in-3-steps/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Building end-to-end pipelines is becoming more important as many businesses realize that having a machine learning model is only one small step towards getting their ML-driven application into production.&nbsp;&lt;/p&gt;&lt;p&gt;Google Cloud offers a tool for training and deploying models at scale, &lt;a href="https://cloud.google.com/ai-platform"&gt;Cloud AI Platform&lt;/a&gt;, which integrates with multiple orchestration tools like &lt;a href="https://www.tensorflow.org/tfx" target="_blank"&gt;TensorFlow Extended&lt;/a&gt; and &lt;a href="https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/" target="_blank"&gt;KubeFlow Pipelines&lt;/a&gt; (KFP). However, it is often the case that businesses have models which they have built in their own ecosystem using frameworks like &lt;a href="https://scikit-learn.org/stable/" target="_blank"&gt;scikit-learn&lt;/a&gt; and &lt;a href="https://xgboost.readthedocs.io/en/latest" target="_blank"&gt;xgboost&lt;/a&gt;, and porting these models to the cloud can be complicated and time consuming.&nbsp;&lt;/p&gt;&lt;p&gt;Even for experienced ML practitioners on Google Cloud Platform (GCP),&nbsp; migrating a scikit-learn model (or equivalent) to AI Platform can take a long time due to all the boilerplate that is involved. &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python" target="_blank"&gt;ML Pipeline Generator&lt;/a&gt; is a tool that allows users to easily deploy existing ML models on GCP, where they can then benefit from serverless model training and deployment and a faster time to market for their solutions.&lt;/p&gt;&lt;p&gt;This blog will provide an overview of how this solution works and the expected user journey, and instructions for orchestrating a TensorFlow training job on AI Platform.&nbsp;&lt;/p&gt;&lt;h2&gt;Overview&lt;/h2&gt;&lt;p&gt;ML Pipeline Generator allows users with pre-built scikit-learn, xgboost, and TensorFlow models to quickly generate and run an end-to-end ML pipeline on GCP using their own code and data.&nbsp;&lt;/p&gt;&lt;p&gt;In order to do this, users must fill in a config file describing their code's metadata. The library takes this config file and generates all the necessary boilerplate for the user to train and deploy their model on the cloud in an orchestrated fashion using a templating engine. In addition, users who train TensorFlow models can use the &lt;a href="https://cloud.google.com/explainable-ai"&gt;Explainable AI&lt;/a&gt; feature to better understand their model.&lt;/p&gt;&lt;p&gt;In the figure below, we highlight the architecture of the generated pipeline. The user will bring their own data, define how they perform data preprocessing, and add their ML model file. Once the user fills out the config file, they use a simple python API to generate self-contained boilerplate code which takes care of any preprocessing specified, uploads their data to Google Cloud Storage (GCS), and launches a training job with hyperparameter tuning. Once this is completed, the model is then deployed to be served and, depending on the model type, model explainability is performed. This whole process can be orchestrated using Kubeflow Pipelines.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/An_Overview_of_the_ML_Pipeline_Generator.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="An Overview of the ML Pipeline Generator.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/An_Overview_of_the_ML_Pipeline_Generator.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Click to enlarge&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h2&gt;Step-by-step instructions&lt;/h2&gt;&lt;p&gt;We’ll demonstrate how you can build an end-to-end Kubeflow Pipeline for training and serving a model, given the model config parameters and the model code. We will build a pipeline to train a shallow TensorFlow model on the &lt;a href="https://archive.ics.uci.edu/ml/datasets/Census+Income" target="_blank"&gt;Census Income Data Set&lt;/a&gt;. The model will be trained on Cloud AI Platform and can be monitored in the Kubeflow UI.&nbsp;&lt;/p&gt;&lt;h3&gt;Before you begin&lt;/h3&gt;&lt;p&gt;To ensure that you are able to fully use the solution, you need to set up a few items on GCP:&lt;/p&gt;1. You’ll need a Google Cloud project to run this demo. We recommend &lt;a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project"&gt;creating a new project&lt;/a&gt; and ensure the following APIs &lt;a href="https://console.cloud.google.com/flows/enableapi?apiid=compute.googleapis.com,ml.googleapis.com,storage-component.googleapis.com&amp;amp;_ga=2.177168930.624614287.1583211899-1966012887.1583211899"&gt;are enabled&lt;/a&gt; for the project:&nbsp;&lt;br/&gt;&lt;ol&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Compute Engine&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI Platform Training and Prediction&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Cloud Storage &lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;p&gt;2. Install the &lt;a href="https://cloud.google.com/sdk/install#installation_options"&gt;Google Cloud SDK&lt;/a&gt; so that you can access required GCP services via the command line. Once the SDK is installed, set up application default credentials with the project ID of the project you created above.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;3. If you’re looking to deploy your ML model on Kubeflow Pipelines using this solution, create a new KFP instance on &lt;a href="https://console.cloud.google.com/ai-platform/pipelines"&gt;AI Platform Pipelines&lt;/a&gt; in your project. Note down the instance’s hostname (Dashboard URL of the form &lt;code&gt;[vm-hash]-dot-[zone].pipelines.googleusercontent.com&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;4. Lastly, &lt;a href="https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-console"&gt;create a bucket&lt;/a&gt; so that data and the models can be stored on GCS. Note down the bucket ID.&lt;/p&gt;&lt;h3&gt;Step 1: Setting up the environment&lt;/h3&gt;&lt;p&gt;Clone the github repo for the demo code, and create a Python virtual environment.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Install the &lt;a href="https://pypi.org/project/ml-pipeline-gen/0.0.5/" target="_blank"&gt;ml-pipeline-gen&lt;/a&gt; package.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;The following files are of interest to us to be able to get our model up and running:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1. The&nbsp;&lt;code&gt;examples/&lt;/code&gt; directory contains sample code for sklearn, Tensorflow and XGBoost models. We will use the &lt;code&gt;examples/kfp/model/tf_model.py&lt;/code&gt;&nbsp; to deploy a TensorFlow model on Kubeflow Pipelines. However, if you are using your own model you can modify the &lt;code&gt;tf_model.py&lt;/code&gt; file with your model code.&nbsp;&lt;/p&gt;&lt;p&gt;2. The&nbsp;&lt;code&gt;examples/kfp/model/census_preprocess.py&lt;/code&gt; downloads the Census Income dataset and preprocesses it for the model. For your custom model, you can modify the preprocessing script as required.&nbsp;&lt;/p&gt;&lt;p&gt;3. The tool relies on a &lt;code&gt;config.yaml&lt;/code&gt; file for the required metadata to build artifacts for the pipeline. Open the &lt;code&gt;examples/kfp/config.yaml.example&lt;/code&gt; template file to see the sample metadata parameters and you can find the detailed schema &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python/blob/master/docs/CONFIG.md" target="_blank"&gt;here&lt;/a&gt;.&nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;4. If you’re looking to use Cloud AI Platform’s hyperparameter tuning feature, you can include the parameters in a &lt;code&gt;hptune_config.yaml&lt;/code&gt; file and add its path in &lt;code&gt;config.yaml&lt;/code&gt;. You can check out the schema for &lt;code&gt;hptune_config.yaml&lt;/code&gt; &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python/blob/master/docs/HPTUNE_CONFIG.md" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Step 2: Setting up required parameters&lt;/h3&gt;&lt;p&gt;1. Make a copy of the &lt;code&gt;kfp/&lt;/code&gt; example directory&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;2. Create a &lt;code&gt;config.yaml&lt;/code&gt; file using the &lt;code&gt;config.yaml.example&lt;/code&gt; template and update the following parameters with the project ID, bucket ID, the KFP hostname you noted down earlier, and a model name.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Step 3: Building the pipeline and training the model&lt;/h3&gt;&lt;p&gt;With the config parameters in place, we’re ready to generate modules that will build the pipeline to train the TensorFlow model. Run the &lt;code&gt;demo.py&lt;/code&gt; file.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;The first time you run the Kubeflow Pipelines demo, the tool provisions &lt;a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity"&gt;Workload Identity&lt;/a&gt; for the GKE cluster which modifies the dashboard URL. To deploy your model, simply update the URL in &lt;code&gt;config.yaml&lt;/code&gt; and run the demo again.&nbsp;&lt;/p&gt;&lt;p&gt;The &lt;code&gt;demo.py&lt;/code&gt; script downloads the census dataset from a public Cloud Storage bucket, prepares the datasets for training and evaluation as per &lt;code&gt;examples/kfp/model/census_preprocess.py&lt;/code&gt;, uploads the dataset to the Cloud Storage URLs specified in &lt;code&gt;config.yaml&lt;/code&gt;, builds the pipeline graph for training and uploads the graph on the Kubeflow Pipelines application instance as an experiment.&nbsp;&lt;/p&gt;&lt;p&gt;Once the graph has been submitted for a run, you can monitor the progress of the run in the Kubeflow Pipelines UI. Open the &lt;a href="http://console.cloud.google.com/ai-platform/pipelines" target="_blank"&gt;Cloud AI Platform Pipelines&lt;/a&gt; page and open the Dashboard for your Kubeflow Pipelines cluster.&lt;/p&gt;&lt;p&gt;Note:&lt;/p&gt;&lt;p&gt;If you would like to use the Scikit-learn or XGBoost examples, you can follow the same steps above, but modify the &lt;code&gt;examples/sklearn/config.yaml&lt;/code&gt; with similar changes as above without the additional step of creating a Kubeflow Pipelines instance. For more details, refer to the instructions in the &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python#cloud-ai-platform-demo" target="_blank"&gt;public repo&lt;/a&gt; or follow our end-to-end tutorial written in a &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python/blob/master/examples/getting_started_notebook.ipynb" target="_blank"&gt;Jupyter notebook&lt;/a&gt;.&nbsp;&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this post we showed you how to migrate your custom ML model for training and deployment to Google Cloud in three easy steps. Most of the heavy-lifting is done by the solution, where the user simply needs to bring their data, model definition and state how they would like the training and serving to be handled.&nbsp;&lt;/p&gt;&lt;p&gt;We went through one example in detail and the public repository includes examples for other supported frameworks. We invite you to utilize the tool and start realizing one of the many benefits of Cloud for your Machine Learning workloads. For more details, check out the &lt;a href="https://github.com/GoogleCloudPlatform/ml-pipeline-generator-python#cloud-ai-platform-demo" target="_blank"&gt;public repo&lt;/a&gt;. To learn more about Kubeflow Pipelines and its features, check out &lt;a href="https://www.youtube.com/watch?v=DjP24I_WKWw" target="_blank"&gt;this session&lt;/a&gt; from Google Cloud Next ‘19.&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Acknowledgements&lt;br/&gt;&lt;/i&gt;&lt;/sup&gt;&lt;i&gt;&lt;sup&gt;This work would not have been possible without the hard work of the following people (in alphabetical order of last name): Chanchal Chatterjee, Stefan Hosein, Michael Hu, Ashok Patel and Vaibhav Singh.&lt;/sup&gt;&lt;/i&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/ai-machine-learning/explaining-model-predictions-on-image-data/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_BigQuery_KHi78bE.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Explaining model predictions on image data&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;A conceptual overview and technical deep dive into how XAI works on image data&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 24 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/ai-machine-learning/migrate-your-custom-ml-models-to-google-cloud-in-3-steps/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    AI &amp; Machine Learning
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_B3.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Migrate your custom ML models to Google Cloud in 3 steps</title>
    <description>
     How to migrate your custom ML models to Google Cloud in 3 steps using Kubeflow Pipelines.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_B3.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/ai-machine-learning/migrate-your-custom-ml-models-to-google-cloud-in-3-steps/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Stefan Hosein
    </name>
    <title>AI Engineer</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Michael Hu
    </name>
    <title>AI Engineer</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Modern detection for modern threats: Changing the game on today’s threat actors</title>
   <link>
    https://cloud.google.com/blog/products/identity-security/introducing-chronicle-detect-from-google-cloud/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;2020 has introduced complex challenges for enterprise IT environments. Data volumes have grown, attacker techniques have become complex yet more subtle, and existing detection and analytics tools struggle to keep up.&nbsp;&lt;/p&gt;&lt;p&gt;In legacy security systems, it’s difficult to run many rules in parallel and at scale—so even if detection is possible, it may be too late. Most analytics tools use a data query language, making it difficult to write detection rules described in scenarios such as the Mitre ATT&amp;amp;CK framework. Finally, detections often require threat intelligence on attacker activity that many vendors simply don’t have. As a result, security tools are unable to detect many modern threats.&lt;/p&gt;&lt;p&gt;To address these needs, today at &lt;a href="https://cloudonair.withgoogle.com/events/security-talks-september-2020" target="_blank"&gt;Google Cloud Security Talks&lt;/a&gt; we're announcing Chronicle Detect, a threat detection solution built on the power of Google’s infrastructure to help enterprises identify threats at unprecedented speed and scale. Earlier this year at RSA, we introduced the building blocks for Chronicle Detect: a data fusion model that stitches events into a unified timeline, a rules engine to handle common events, and a language for describing complex threat behaviors. With today’s announcement, we complete the rest of the solution.&lt;br/&gt;&lt;/p&gt;&lt;p&gt;"The scale and SaaS deployment model of Google Chronicle drove NCR's initial interest and investment. Their speed to deliver new features and integration have kept us productive and continued to impress. By operationalizing Chronicle for threat investigations, we have significantly improved our detection metrics. As an early design partner with Chronicle around its rules engine, Chronicle Detect, we see a clear opportunity to extend its benefits and impact to advanced threat detection."—Bob Varnadoe, CISO at NCR Corporation&lt;/p&gt;&lt;h3&gt;Introducing Chronicle’s next generation rules engine&lt;/h3&gt;&lt;p&gt;Chronicle Detect brings modern threat detection to enterprises with the next generation of our rules engine that operates at the speed of search, a widely-used language designed specifically for describing threat behaviors, and a regular stream of new rules and indicators, built by our research team.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/chronicle_detect.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="chronicle detect.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/chronicle_detect.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Chronicle Detect makes it easy for enterprises to move from legacy security tools to a modern threat detection system. Using our Google-scale platform, security teams can send their security telemetry to Chronicle at a fixed cost so that diverse, high value security data can be taken into account for detections. We automatically make that security data useful by mapping it to a common data model across machines, users, and threat indicators, so that you can quickly apply powerful detection rules to a unified set of data.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/Detection_rules_trigger.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="Detection rules trigger.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Detection_rules_trigger.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Detection rules trigger based on high value security telemetry sent to the Chronicle platform.&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;With Chronicle Detect, you can use advanced rules out-of-the-box, build your own, or migrate rules over from legacy tools. The rules engine incorporates one of the most flexible and widely-used detection languages in the world, YARA, which makes it easy to build detections for tactics and techniques found in the commonly used MITRE ATT&amp;amp;CK security framework. YARA-L, a language for describing threat behaviors, is the foundation of the Chronicle Detect rules engine. Many organizations are also integrating Sigma-based rules that work across systems, or converting their legacy rules to Sigma for portability. Chronicle Detect includes a Sigma-YARA converter so that customers can port their rules to and from our platform.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/Using_the_YARA-L_language.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="Using the YARA-L language.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Using_the_YARA-L_language.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Using the YARA-L language, it's easy to edit and build detection rules in the Chronicle interface.&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Get real-time threat indicators and automatic rules from Uppercase&nbsp;&lt;/h3&gt;&lt;p&gt;Chronicle customers can also take advantage of detection rules and threat indicators from Uppercase, Chronicle’s dedicated threat research team. Uppercase researchers leverage a variety of novel tools, techniques, and data sources (including Google threat intelligence and a number of industry feeds) to provide Chronicle customers with indicators spanning the latest crimeware, APTs, and unwanted malicious programs. The Uppercase-provided IOCs—such as high-risk IPs, hashes, domains, registry keys—are analyzed against all security telemetry in your Chronicle system, and let you know right away when high-risk threat indicators are present in your environment.&lt;/p&gt;&lt;p&gt;“As an early adopter, Quanta has benefited from Chronicle’s scale, performance and economic benefits in security investigations and threat hunting. We are excited to see Chronicle extend the Google advantage to threat detection with the launch of Chronicle Detect backed by the Chronicle Uppercase research team.” —James Stinson, VP IT at Quanta Services, Inc&lt;/p&gt;&lt;p&gt;The combination of these capabilities helps enterprises uncover multi-event attacks in their systems such as a new email sender followed by an HTTP post to a rare domain, or a suspiciously long powershell script accessing a low prevalence domain.&nbsp;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Chronicle Detect.gif" src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/chronicle_detect.gif"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Since joining Google Cloud over a year ago, the Chronicle team has been innovating on our investigation and hunting platform to bring a new set of capabilities to the security market—and we won’t stop here. Chronicle has also added new global availability and data localization options, including data center support for all capabilities in Europe and the Asia Pacific region. &nbsp;&lt;/p&gt;&lt;p&gt;We’ll continue to build out integrations and help enterprises uncover threats with Chronicle wherever their data and applications reside, on-premises, in Google Cloud, and even in other cloud environments. To learn more about Chronicle Detect, read the&nbsp;&lt;a href="https://medium.com/@chroniclesec/introducing-chronicle-detect-ef16dd324434" target="_blank"&gt;Chronicle blog&lt;/a&gt;&nbsp;or&nbsp;&lt;a href="https://go.chronicle.security/contact" target="_blank"&gt;contact the Chronicle sales team&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/identity-security/helping-you-modernize-security-in-the-cloud/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_security_1.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;A better, safer normal: Helping you modernize security in the cloud or in place&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;We're sharing more on unique and powerful capabilities Google Cloud has to simplify security operations in your organization.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Wed, 23 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/identity-security/introducing-chronicle-detect-from-google-cloud/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Identity &amp; Security
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Chronicle.max-600x600.png" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Modern detection for modern threats: Changing the game on today’s threat actors</title>
    <description>
     Chronicle Detect, a threat detection solution built on the power of Google’s infrastructure, can help enterprises identify threats at unprecedented speed and scale.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Chronicle.max-600x600.png
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/identity-security/introducing-chronicle-detect-from-google-cloud/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Rick Caccia
    </name>
    <title>Head of Marketing, Cloud Security</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Sunil Potti
    </name>
    <title>General Manager and VP of Engineering, Cloud Security</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>SRE Classroom: exercises for non-abstract large systems design</title>
   <link>
    https://cloud.google.com/blog/products/devops-sre/join-sre-classroom-nalsd-workshops/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Have you ever tried your hand at designing a resilient distributed software system? If you have, you likely found that there are many factors that contribute to the overall reliability of a system. Different parts of the system can fail in varied and unexpected ways. Certain architecture patterns work well in some situations, but poorly in others. There are many tradeoffs to be made about which parts of the system to optimize and when to optimize them.&lt;/p&gt;&lt;p&gt;Navigating the many nuances of designing a distributed system can be daunting. However, anyone can be equipped to tackle these problems with the right tools and practice. There are many ways to design distributed systems. One way involves growing systems organically, adding and rewriting components as the system handles more requests or changes scope. At Google, we use a method called &lt;a href="https://landing.google.com/sre/workbook/chapters/non-abstract-design/" target="_blank"&gt;non-abstract large system design&lt;/a&gt; (NALSD). NALSD is an iterative process for designing, assessing, and evaluating distributed systems such as the &lt;a href="https://research.google/pubs/pub43438" target="_blank"&gt;Borg cluster management for distributed computing&lt;/a&gt; and the &lt;a href="https://research.google/pubs/pub51" target="_blank"&gt;Google distributed file system&lt;/a&gt;. With this in mind, we’ve developed exercises to provide hands-on experience with the NALSD techniques.&nbsp;&lt;/p&gt;&lt;p&gt;NALSD exercises are designed to equip engineers with the foundational knowledge and problem-solving skills needed to design planet-scale systems. You’ll learn how to evaluate whether a particular design achieves a service’s required &lt;a href="https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos"&gt;service-level objectives (SLOs)&lt;/a&gt;. These workshops challenge you to translate abstract designs into concrete plans using back-of-the-envelope calculations. Most importantly, they provide a chance for you to put these abstract concepts into practice.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-pull_quote"&gt;&lt;div class="uni-pull-quote h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;div class="uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;div class="uni-pull-quote__inner-wrapper h-c-copy h-c-copy"&gt;&lt;q class="uni-pull-quote__text"&gt;Planet-scale system (noun): A system that delivers services to users, no matter where they are around the world. Such a system delivers its services reliably, with high performance and availability to all of its users&lt;/q&gt;&lt;/div&gt;&lt;/div&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;SRE Classroom and the first NALSD workshop&lt;/h3&gt;&lt;p&gt;Developed by Google engineers, &lt;a href="https://landing.google.com/sre/workbook/chapters/non-abstract-design/" target="_blank"&gt;SRE Classroom is a workshop series&lt;/a&gt; designed to drive understanding of concepts like NALSD and &lt;a href="https://cloud.google.com/blog/products/gcp/sre-fundamentals-slis-slas-and-slos"&gt;other core SRE principles&lt;/a&gt;. Over the past few years, these workshops—taught within Google and at external conferences—have helped numerous engineers improve their system design and thinking skills. Our mission is to ensure engineering teams everywhere can understand and apply these concepts and best practices to their own systems.&lt;/p&gt;&lt;p&gt;We’re pleased to make available all of the materials for our &lt;a href="https://landing.google.com/sre/resources/sre-classroom/" target="_blank"&gt;Distributed Pub/Sub workshop&lt;/a&gt;—the first of our NALSD-focused exercises from SRE Classroom. You can now freely use and re-use this material, available under the Creative Commons &lt;a href="http://creativecommons.org/licenses/by/4.0/" target="_blank"&gt;CC-BY 4.0&lt;/a&gt; license, as long as Google is credited as the original author. Run your own version of this workshop and teach your coworkers, customers, or conference attendees about how to design large-scale distributed systems!&lt;/p&gt;&lt;h3&gt;What’s covered in the Distributed PubSub workshop&lt;/h3&gt;&lt;p&gt;The PubSub exercise is about designing a planet-scale asynchronous publish-subscribe communication system. The workshop presents the problem statement, describes the requirements and available infrastructure, and walks through a sample solution.&lt;/p&gt;&lt;p&gt;The workshop and material is broken into three stages:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Design a working solution for a single data center.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Extend that design to multiple data centers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Provision the system (i.e., how much hardware and bandwidth do we need?).&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;For each stage of the workshop, participants will work through their own solution first. After they have a chance to explore their own ideas, the workshop leader presents a sample solution along with reasons for why certain design decisions were made.&lt;/p&gt;&lt;p&gt;The exercise covers a wide variety of topics related to distributed system design, including scaling, replication, sharding, consensus, availability, consistency, distributed architecture patterns (such as microservices), and more. We present these concepts in contexts where they are useful to solving the problem at hand: designing a system to meet specific requirements. This helps bring clarity to where and why a particular concept might be useful for solving a particular problem.&lt;/p&gt;&lt;p&gt;Typically, when we run this workshop, we break participants up into groups of four to six to work collaboratively toward a solution. Each group is paired with an experienced SRE volunteer who facilitates the discussion, encourages participation, and keeps the group on track.&lt;/p&gt;&lt;h3&gt;Run your own PubSub workshop!&lt;/h3&gt;&lt;p&gt;If this sounds interesting, check out the &lt;a href="https://googlesre.page.link/sre-classroom-presenter-guide" target="_blank"&gt;Presenter Guide&lt;/a&gt; and the &lt;a href="https://googlesre.page.link/facilitator-guide" target="_blank"&gt;Facilitator Guide&lt;/a&gt;, which have a lot more information on how to organize a Distributed Pub/Sub workshop. If you don't have a whole team to educate, you can also work through this exercise with a buddy or on your own. Exploring multiple solutions to the problem and identifying the pros and cons of each solution may also be a meaningful exercise.&lt;/p&gt;&lt;p&gt;&lt;a href="http://google.com/sre" target="_blank"&gt;Learn more about SRE&lt;/a&gt; and industry-leading practices for service reliability.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/gcp/sre-fundamentals-slis-slas-and-slos/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/061-GC-SRE-Fundamentals-Header.max-500x500.png')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;SRE fundamentals: SLIs, SLAs and SLOs&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Next week at&nbsp;Google Cloud Next ‘18, you’ll be hearing about new ways to think about and ensure the availability of your applications. A b...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Wed, 23 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/devops-sre/join-sre-classroom-nalsd-workshops/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    DevOps &amp; SRE
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/SRE_classroom.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>SRE Classroom: exercises for non-abstract large systems design</title>
    <description>
     Learn how to apply SRE principles in this series of workshops on non-abstract large systems design (NALSD) with Google engineers.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/SRE_classroom.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/devops-sre/join-sre-classroom-nalsd-workshops/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Jenny Liao
    </name>
    <title>Software Engineer</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Salim Virji
    </name>
    <title>Site Reliability Engineer</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Cloud Run for Anthos brings eventing to your Kubernetes microservices</title>
   <link>
    https://cloud.google.com/blog/products/serverless/cloud-run-for-anthos-adds-events/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Building microservices on Google Kubernetes Engine (GKE) provides you with maximum flexibility to build your applications, while still benefiting from the scale and toolset that Google Cloud has to offer. But with great flexibility comes great responsibility. Orchestrating microservices can be difficult, requiring non-trivial implementation, customization, and maintenance of messaging systems.&nbsp;&lt;/p&gt;&lt;p&gt;Cloud Run for Anthos now includes an events feature that allows you to easily build event-driven systems on Google Cloud. Now in beta, Cloud Run for Anthos’ event feature assumes responsibility for the implementation and management of eventing infrastructure, so you don’t have to.&lt;/p&gt;&lt;p&gt;With events in Cloud Run for Anthos, you get&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;The ability to &lt;b&gt;trigger a service on your GKE cluster&lt;/b&gt; without exposing a public HTTP endpoint&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Support for Google Cloud Storage, Cloud Scheduler, Pub/Sub, and &lt;b&gt;60+ Google services&lt;/b&gt; through Cloud Audit logs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Custom events generated by your code to &lt;b&gt;signal between services&lt;/b&gt; through a standardized eventing infrastructure&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A consistent developer experience, as all events, regardless of the source, follow the &lt;a href="https://cloudevents.io/" target="_blank"&gt;CloudEvents&lt;/a&gt; standard&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You can use events for Cloud Run for Anthos for a number of exciting use cases, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Use a &lt;b&gt;Cloud Storage event&lt;/b&gt; to trigger a data processing pipeline, creating a loosely coupled system with the minimum effort.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use a &lt;b&gt;BigQuery&lt;/b&gt; audit log event to initiate a process each time a data load completes, loosely coupling services through the data they write.&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use a &lt;b&gt;Cloud Scheduler event&lt;/b&gt; to trigger a batch job. This allows you to focus on the code of what that job is doing and not its scheduling.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use &lt;b&gt;Custom Events&lt;/b&gt; to directly signal between microservices, leveraging the same standardized infrastructure for any asynchronous coordination of services.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-video"&gt;&lt;div class="article-module article-video "&gt;&lt;figure&gt;&lt;a class="h-c-video h-c-video--marquee" data-glue-modal-disabled-on-mobile="true" data-glue-modal-trigger="uni-modal-0N82S5fXpQE-" href="https://youtube.com/watch?v=0N82S5fXpQE"&gt;&lt;img alt="Cloud Run is great for running containers in a serverless way but how do you feed events to those containers? Events for Cloud Run provides primitives to build event-driven architectures. This provides an opportunity to read Google Cloud and 3rd party events in a consistent way and to choose where to consume those events either in Google Cloud or other clouds with Anthos. In this session, get an overview of Events for Cloud Run and its Knative compatible Anthos version. Watch now to learn the building blocks Cloud Run provides for event-driven architectures" src="//img.youtube.com/vi/0N82S5fXpQE/maxresdefault.jpg"/&gt;&lt;svg class="h-c-video__play h-c-icon h-c-icon--color-white" role="img"&gt;&lt;use xlink:href="#mi-youtube-icon"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="h-c-modal--video" data-glue-modal="uni-modal-0N82S5fXpQE-" data-glue-modal-close-label="Close Dialog"&gt;&lt;a class="glue-yt-video" data-glue-yt-video-autoplay="true" data-glue-yt-video-height="99%" data-glue-yt-video-vid="0N82S5fXpQE" data-glue-yt-video-width="100%" href="https://youtube.com/watch?v=0N82S5fXpQE" ng-cloak=""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;How it works&lt;/h3&gt;Cloud Run for Anthos lets you run serverless workloads on Kubernetes, leveraging the power of GKE. This new events feature is no different, offering standardized infrastructure to manage the flow of events, letting you focus on what you do best: building great applications. The solution is based on open-source primitives (Knative), avoiding vendor-lock-in while still providing the convenience of a Google-managed solution. &lt;br/&gt;&lt;br/&gt;Let’s see events in action. This demo app builds a BigQuery processing pipeline to query a dataset on a schedule, create charts out of the data and then notify users about the new charts via SendGrid. You can find &nbsp;the demo on &lt;a href="https://github.com/meteatamel/cloudrun-tutorial/blob/master/docs/bigquery-processing-pipeline-gke.md" target="_blank"&gt;github&lt;/a&gt;.&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="BigQuery processing pipeline.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/BigQuery_processing_pipeline.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;You’ll notice in the example above that the services do not communicate directly with each other, instead we use events on Cloud Run for Anthos to ‘wire up’ coordination between these services, like so:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="cloud run for anthos.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/events_on_Cloud_Run_for_Anthos.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Let’s break this demo down further.&nbsp;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 1- Create the Trigger for Query Runner&lt;/b&gt;: First, create a trigger targeting the Query runner service based on a cloud scheduler job.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Signal the notifier service based on a GCS event.gif" src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/Signal_the_notifier_service_based_on_a_GCS_event.gif"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Step 2- Handle the event in your code&lt;/b&gt;: In our example we need details provided in the trigger. These are delivered via the HTTP header and body of the request and can easily be unmarshalled using the CloudEvent SDK and libraries. In this example, we use C#:&lt;/p&gt;&lt;p&gt;Read the event using &lt;a href="https://github.com/cloudevents/sdk-csharp" target="_blank"&gt;CloudEvent SDK&lt;/a&gt;:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Parse the CloudEvent Data using &lt;a href="https://github.com/googleapis/google-cloudevents" target="_blank"&gt;Google Events&lt;/a&gt; library for C#:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Step 3 - Signal the Chart Creator with a custom event&lt;/b&gt;: Using custom events we can easily signal a downstream service without having to maintain a backend. In this example we raise an event of type &lt;code&gt;dev.knative.samples.querycompleted&lt;/code&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Then we create a trigger for the Chart Creator service that fires when that custom event occurs. In this example we use the following gcloud command to create the trigger:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Step 4 - Signal the notifier service based on a GCS event&lt;/b&gt;: We can trigger the notifier service once the charts have been written to the storage service by simply creating a Cloud Storage trigger.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Create the Trigger for Query Runner.gif" src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/Create_the_Trigger_for_Query_Runner.gif"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;And there you have it! From this example you can see how with events for Cloud Run for Anthos, it’s easy to build a standardized event-based architecture, without having to manage the underlying infrastructure. To learn more and get started, you can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Get started with &lt;a href="https://cloud.google.com/run/docs/events/anthos/quickstart"&gt;Events for Cloud Run for Anthos&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Follow along with our demo in &lt;a href="https://google.qwiklabs.com/catalog_lab/3014" target="_blank"&gt;our Qwiklab&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;View our &lt;a href="https://www.youtube.com/watch?time_continue=9&amp;amp;v=0N82S5fXpQE&amp;amp;feature=emb_logo" target="_blank"&gt;recorded talk at Next 2020&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/serverless/new-features-in-cloud-run-for-anthos-ga/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_CkvXMRW.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;What’s new in Cloud Run for Anthos&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;The GA of Cloud Run for Anthos includes several new features&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Wed, 23 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/serverless/cloud-run-for-anthos-adds-events/
   </guid>
   <category>
    Containers &amp; Kubernetes
   </category>
   <category>
    Application Development
   </category>
   <category>
    Hybrid Cloud
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Serverless
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Serverless_computing.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Cloud Run for Anthos brings eventing to your Kubernetes microservices</title>
    <description>
     New eventing capabilities in Cloud Run for Anthos make it easy to build event-driven applications on top of your GKE environment.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Serverless_computing.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/serverless/cloud-run-for-anthos-adds-events/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Mete Atamel
    </name>
    <title> Developer Advocate</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Bryan Zimmerman
    </name>
    <title>Product Manager</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Are you an Elite DevOps performer? Find out with the Four Keys Project</title>
   <link>
    https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Through six years of research, the &lt;a href="https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling"&gt;DevOps Research and Assessment (DORA)&lt;/a&gt; team has identified four key metrics that indicate the performance of a software development team:&nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Deployment Frequency&lt;/b&gt; - How often an organization successfully releases to production&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Lead Time for Changes&lt;/b&gt; - The amount of time it takes a commit to get into production&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Change Failure Rate&lt;/b&gt; - The percentage of deployments causing a failure in production&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Time to Restore Service&lt;/b&gt; - How long it takes an organization to recover from a failure in production&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;At a high level, Deployment Frequency and Lead Time for Changes measure velocity, while Change Failure Rate and Time to Restore Service measure stability. And by measuring these values, and continuously iterating to improve on them, a team can achieve significantly better business outcomes. DORA, for example, uses these metrics to identify Elite, High, Medium and Low performing teams, and finds that Elite teams are twice as likely to meet or exceed their organizational performance goals.&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Baselining your organization’s performance on these metrics is a great way to improve the efficiency and effectiveness of your own operations. But how do you get started? The journey starts with gathering data. To help you generate these metrics for your team, we created the &lt;a href="https://github.com/GoogleCloudPlatform/fourkeys" target="_blank"&gt;Four Keys&lt;/a&gt; open source project, which automatically sets up a data ingestion pipeline from your Github or Gitlab repos through Google Cloud services and into Google DataStudio. It then aggregates your data and compiles it into a dashboard with these key metrics, which you can use to track your progress over time.&nbsp;&lt;/p&gt;&lt;p&gt;To use the Four Keys project, we’ve included a &lt;a href="https://github.com/GoogleCloudPlatform/fourkeys/blob/master/setup/INSTALL.md" target="_blank"&gt;setup script&lt;/a&gt; in the repo to make it easy to collect data from the default sources and view your DORA metrics. For anyone interested in contributing to the project or customizing it to their own team’s use cases, we’ve outlined the three key components below: the pipeline, the metrics, and the dashboard.&nbsp;&lt;/p&gt;&lt;h3&gt;The Four Keys pipeline&lt;/h3&gt;&lt;p&gt;The Four Keys pipeline is the ETL pipeline which collects your DevOps data and transforms it into DORA metrics.&lt;/p&gt;&lt;p&gt;One of the challenges of gathering these DORA metrics, however, is that, for any one team (let alone all the teams in an organization), deployment, change, and incident data are usually in different disparate systems. How do we develop an open-source tool that can capture data from these different sources—as well as from sources that you may want to use in the future?&nbsp;&lt;/p&gt;&lt;p&gt;With Four Keys, our solution was to create a generalized pipeline that can be extended to process inputs from a wide variety of sources. Any tool or system that can output an HTTP request can be integrated into the Four Keys pipeline, which receives events via webhooks and ingests them into BigQuery.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/Four_Keys_pipeline.0805029014550550.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="Four Keys pipeline.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Four_Keys_pipeline.0805029014550550.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Click to enlarge&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;In the Four Keys pipeline, known data sources are parsed properly into changes, incidents and deployments. For example, GitHub commits are picked up by the changes script, Cloud Build deployments fall under deployments, and GitHub issues with an ‘incident’ label are categorized as incidents. If a new data source is added and the existing queries do not categorize it properly, the developer can recategorize it by editing the SQL script.&lt;/p&gt;&lt;h3&gt;Data extraction and transformation&lt;/h3&gt;&lt;p&gt;Once the raw data is in the data warehouse, there are two challenges: extraction and transformation. To optimize for business flexibility, both of these processes are handled with SQL. Four Keys uses BigQuery scheduled queries to create the downstream tables from the raw events table.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Data extraction and transformation.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Data_extraction_and_transformation.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Four Keys categorizes events into Changes, Deployments, and Incidents using `WHERE` statements, and normalizes and transforms the data with the `SELECT` statement. The precise definition of a change, deployment, or incident depends on a team’s business requirements, making it all the more important to have a flexible way to include or exclude additional events.&lt;/p&gt;&lt;p&gt;While the definition may different from team to team, the scripts do provide defaults to get you started. As an example, here’s the &lt;a href="https://github.com/GoogleCloudPlatform/fourkeys/blob/master/queries/deployments.sql" target="_blank"&gt;Deployments&lt;/a&gt; script:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-code"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid uni-paragraph-wrap"&gt;&lt;div class="uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Four Keys uses the WHERE filter to only pull relevant rows from the events_raw table, and the SELECT statement to map the corresponding fields in the JSON to the commit id. One of the benefits of doing data transformations in BigQuery is that you don’t need to re-run the pipeline to edit or recategorize the data. The JSON_EXTRACT_SCALAR function allows you to parse and manipulate the JSON data in the SQL itself. BigQuery even allows you to write custom javascript functions in SQL!&lt;/p&gt;&lt;h3&gt;Calculating the metrics&lt;/h3&gt;&lt;p&gt;This section discusses how to translate the DORA metrics to systems-level calculations. The original research done by the DORA team surveyed real people rather than gathering systems data and bucketed metric into a performance level, as follows:&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/Calculating_the_metrics.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="Calculating the metrics.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Calculating_the_metrics.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Click to enlarge&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;However, it’s a lot easier to ask a person how frequently they deploy than it is to ask a computer! When asked if they deploy daily, weekly, monthly, etc., a DevOps manager usually has a gut feeling which bucket their organization falls into. However, when you demand the same information from a computer, you have to be very explicit about your definitions and make value judgments.&nbsp;&lt;/p&gt;&lt;p&gt;Let’s look at some of the nuances in the metrics definitions and calculations.&lt;/p&gt;&lt;h3&gt;Deployment frequency&lt;/h3&gt;&lt;p&gt;`How &lt;b&gt;often&lt;/b&gt; an organization &lt;b&gt;successfully&lt;/b&gt; releases to &lt;b&gt;production&lt;/b&gt;.`&lt;/p&gt;&lt;p&gt;Deployment Frequency is the easiest metric to collect, because it only needs one table.&nbsp; However, the bucketing for frequency is also one of the trickier elements to calculate. It would be simple and straightforward to show daily deployment volume or to grab the average number of deployments per week, but the metric is deployment frequency, not volume.&nbsp;&nbsp;&lt;/p&gt;&lt;p&gt;In the Four Keys scripts, Deployment Frequency falls into the Daily bucket when the median number of days per week with at least one successful deployment is equal to or greater than three. To put it more simply, to qualify for “deploy daily,” you must deploy on most working days. Similarly, if you deploy most weeks, it will be weekly, and then monthly and so forth.&lt;/p&gt;&lt;p&gt;Next you have to consider what constitutes a successful deployment to production. Do you&nbsp; include deployments that are only to 5% traffic? 80%? Ultimately, this depends on your team’s individual business requirements. By default, the dashboard includes any successful deployment to any level of traffic, but this threshold can be adjusted by editing the SQL scripts in the project.&nbsp;&lt;/p&gt;&lt;h3&gt;Lead Time for Changes&lt;/h3&gt;&lt;p&gt;`The amount of &lt;b&gt;time&lt;/b&gt; it takes a &lt;b&gt;commit&lt;/b&gt; to get into &lt;b&gt;production&lt;/b&gt;`&lt;/p&gt;&lt;p&gt;Lead Time to Changes metric requires two important pieces of data: when the commit happened, and when the deployment happened. This means that for every deployment, you need to maintain a list of all the changes included in the deployment. This is easily done by using triggers with a SHA mapping back to the commits. With the list of changes in the deploy table, you can join back to the changes table to get the timestamps, and then calculate the median lead time.&nbsp;&lt;/p&gt;&lt;h3&gt;Change Failure Rate&lt;/h3&gt;&lt;p&gt;`The &lt;b&gt;percentage&lt;/b&gt; of &lt;b&gt;deployments&lt;/b&gt; causing a &lt;b&gt;failure&lt;/b&gt; in production`&lt;/p&gt;&lt;p&gt;The Change Failure Rate depends on two things: how many deployments were attempted, and how many resulted in failures in production? To get this number, Four Keys needs the total count of deployments—easily acquired from the deployment table—and then links it to incidents. An incident may come from bugs or labels on github incidents, a form to spreadsheet pipeline, an issue management system, etc. The only requirement is that it contain the ID of the deployment so we can join the two tables together.&nbsp;&lt;/p&gt;&lt;h3&gt;Time to Restore Services&lt;/h3&gt;&lt;p&gt;`How &lt;b&gt;long&lt;/b&gt; it takes an organization to &lt;b&gt;recover&lt;/b&gt; from a &lt;b&gt;failure&lt;/b&gt; in production`&lt;/p&gt;&lt;p&gt;To measure the Time to Restore Services, you need to know when the incident was created and when it was resolved. You also need to know when the incident was created and when a deployment resolved said incident. Similar to the last metric, this data could come from any incident management system.&nbsp;&lt;/p&gt;&lt;h3&gt;The dashboard&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;a href="https://storage.googleapis.com/gweb-cloudblog-publish/images/The_dashboard.max-2800x2800.jpg" rel="external" target="_blank"&gt;&lt;img alt="The dashboard.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/The_dashboard.max-1000x1000.jpg"/&gt;&lt;/a&gt;&lt;figcaption class="article-image__caption "&gt;&lt;div class="rich-text"&gt;&lt;i&gt;Click to enlarge&lt;/i&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;With all the data now aggregated and processed in BigQuery, you can visualize it in the Four Keys dashboard. The Four Keys &lt;a href="https://github.com/GoogleCloudPlatform/fourkeys/blob/master/setup/INSTALL.md" target="_blank"&gt;setup script&lt;/a&gt; uses a DataStudio connector, which allows you to connect your data to the Four Keys dashboard template. The dashboard is designed to give you high-level categorizations based on the DORA research for the four key metrics, and also to show you a running log of your recent performance. This allows developer teams to get a sense of a dip in performance early on so they can mitigate it. Alternately, if performance is low, teams will see early signs of progress before the buckets are updated.&nbsp;&lt;/p&gt;&lt;p&gt;Ready to get started?&lt;/p&gt;&lt;p&gt;Please head over to the &lt;a href="https://github.com/GoogleCloudPlatform/fourkeys" target="_blank"&gt;Four Keys&lt;/a&gt; project to try it out. The setup scripts will get you started setting up the architecture and integrating with your projects. We welcome feedback and contributions!&nbsp;&lt;/p&gt;&lt;p&gt;To learn more about how to apply DevOps practices to improve your software delivery performance, visit cloud.google.com/devops. And be on the lookout for a follow-up post on gathering DORA metrics for applications that are hosted entirely in Google Cloud.&lt;/p&gt;&lt;hr/&gt;&lt;i&gt;&lt;sup&gt;1.&nbsp;&lt;a href="https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling"&gt;The 2019 Accelerate State of DevOps: Elite performance, productivity, and scaling&lt;/a&gt;&lt;/sup&gt;&lt;/i&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;The 2019 Accelerate State of DevOps: Elite performance, productivity, and scaling&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;DORA and Google Cloud have published the 2019 Accelerate State of DevOps Report.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Tue, 22 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Open Source
   </category>
   <category>
    DevOps &amp; SRE
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_A_Rnd3.max-2800x2800.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Are you an Elite DevOps performer? Find out with the Four Keys Project</title>
    <description>
     Learn how the Four Keys open source project lets you gauge your DevOps performance according to DORA metrics.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_A_Rnd3.max-2800x2800.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Dina Graves Portman
    </name>
    <title>Developer Programs Engineer</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Better together: Google Cloud Load Balancing, Cloud CDN, and Google Cloud Armor</title>
   <link>
    https://cloud.google.com/blog/products/networking/using-cloud-armor-and-cloud-cdn-with-your-google-load-balancer/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Like many Google Cloud customers, you probably use Global Load Balancing platform to get benefits such as high availability, low latency, and the convenience of a single anycast IP to front-end your global load balancing capacity. But did you know that by adding &lt;a href="https://cloud.google.com/cdn"&gt;Cloud CDN&lt;/a&gt; and &lt;a href="https://cloud.google.com/armor/"&gt;Google Cloud Armor&lt;/a&gt; to your existing Global HTTP(S) load balancer deployment, you can get improved web protection and faster web performance. Read on to learn more.&lt;/p&gt;&lt;h3&gt;Accelerate web performance by enabling Cloud CDN&lt;/h3&gt;&lt;p&gt;At Google we are committed to making the web faster. For example, Cloud Load Balancing supports modern protocols such as &lt;a href="https://en.wikipedia.org/wiki/QUIC" target="_blank"&gt;Google QUIC&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/HTTP/2" target="_blank"&gt;HTTP/2&lt;/a&gt;, which improve performance and reduce latency, especially for users on mobile networks.&nbsp;&lt;/p&gt;&lt;p&gt;Then there’s Cloud &lt;a href="https://cloud.google.com/cdn/"&gt;CDN&lt;/a&gt;, which runs on our globally distributed edge points to reduce network latency by caching content closer to your users. Whenever a request is served from the Cloud CDN cache, the load balancer doesn’t need to retrieve content from the backend infrastructure. This allows you to scale seamlessly and easily handle large spikes in demand (e.g., from holiday shopping). As static web elements such as images, videos, etc., can be served from Google’s global edge instead of your backend systems, your users can enjoy faster page loads and a smoother web experience. Finally, Cloud CDN helps you optimize and reduce the cost of delivery: it keeps load off your web servers, keeping down compute usage, and content served out of Google’s edge cache is billed at a lower egress cost.&nbsp;&lt;/p&gt;&lt;h3&gt;Improve web protection by enabling Cloud Armor&lt;/h3&gt;&lt;p&gt;Google Cloud Armor is the web-application firewall (WAF) and DDoS mitigation service that defends your web apps and services at Google scale. Cloud Armor automatically protects HTTP(S) Load Balancer workloads from volumetric and protocol based DDoS attacks. Users can configure Cloud Armor security policies for custom layer 7 filtering to further protect against application layer attacks.&lt;/p&gt;&lt;p&gt;Cloud Armor helps protect your applications from the threats from the internet while satisfying your organization’s security and compliance requirements and providing near-real time visibility and telemetry about the traffic targeting your applications. With Cloud Armor’s &lt;a href="https://cloud.google.com/armor/docs/rule-tuning"&gt;pre-configured WAF rules&lt;/a&gt;, you can easily help mitigate the OWASP Top 10 web application security risks and prevent exploit attempts such as SQL injection (SQLi), Cross-Site Scripting (XSS), or Remote Code Execution (RCE).&nbsp;&lt;/p&gt;&lt;p&gt;Cloud Armor allows users to customize the behavior of the edge of Google’s network to suit your business needs. Custom rules can be created using our comprehensive &lt;a href="https://cloud.google.com/armor/docs/rules-language-reference"&gt;rules language&lt;/a&gt; to narrowly tailor what traffic is able to reach your web apps or services by filtering on request headers, parameters, and cookies. For example, you can create geography based access controls, leveraging Google’s own geo-ip database, to make your application available only in desired geographies.&nbsp;&lt;/p&gt;&lt;p&gt;We &lt;a href="https://cloud.google.com/blog/products/identity-security/google-cloud-armor-features-to-protect-your-websites-and-applications"&gt;recently launched&lt;/a&gt; Cloud Armor &lt;a href="https://cloud.google.com/armor/docs/managed-protection-overview"&gt;Managed Protection Plus (Beta)&lt;/a&gt;, which is a managed application protection service bundling Cloud Armor WAF, DDoS Mitigation, and Google-curate rules, and other associated services. Managed Protection Plus is offered as a monthly subscription with enterprise-friendly predictable pricing to further help mitigate the impact of DDoS attacks.&nbsp;&lt;/p&gt;&lt;h3&gt;Getting started with enabling Google Cloud Armor and Cloud CDN&nbsp;&lt;/h3&gt;&lt;p&gt;With Google Cloud Load Balancing, Google Cloud Armor and Cloud CDN deployed at the edge, your users can get fast, reliable and secure web delivery with global scale and reach.&lt;/p&gt;&lt;p&gt;Once you have set up the HTTP(S) load balancing, Cloud CDN can be enabled by clicking a single checkbox. For details on how to enable Cloud CDN, look at the &lt;a href="https://cloud.devsite.corp.google.com/cdn/docs/how-to" target="_blank"&gt;Cloud CDN how-to guides&lt;/a&gt;. You can learn more about the benefits of Cloud CDN in this &lt;a href="https://bit.ly/googlecloudcdn" target="_blank"&gt;infographic&lt;/a&gt;.For details on how to enable Cloud Armor for your external HTTP(S) load balancer, look at the &lt;a href="https://cloud.devsite.corp.google.com/armor/docs/how-to" target="_blank"&gt;Google Cloud Armor how-to guides&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/networking/google-cloud-networking-in-depth-cloud-load-balancing-deconstructed/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/GCP_11_JbyEVTk.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Google Cloud networking in depth: Cloud Load Balancing deconstructed&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Take a deeper look at the Google Cloud networking load balancing portfolio.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Mon, 21 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/networking/using-cloud-armor-and-cloud-cdn-with-your-google-load-balancer/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Networking
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_Networking04.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Better together: Google Cloud Load Balancing, Cloud CDN, and Google Cloud Armor</title>
    <description>
     By adding Google Cloud Armor and Cloud CDN to your Global Load Balancer deployment, you can benefit from better security and reduced latency.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_Networking04.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/networking/using-cloud-armor-and-cloud-cdn-with-your-google-load-balancer/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Shubhika Taneja
    </name>
    <title>Product Marketing Manager, Google Cloud</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Emil Kiner
    </name>
    <title>Product Manager, Google Cloud Armor</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Cloud migration: What you need to know (and where to find it)</title>
   <link>
    https://cloud.google.com/blog/products/cloud-migration/guide-to-all-google-cloud-migration-guides/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Migrating to the cloud for an enterprise that has been running workloads on premises for years can be very daunting. To be successful, a migration plan needs to factor in many different aspects relating to people, process and technology. If you are designing the migration, you need guidance and best practices to help steer you through this process.&lt;/p&gt;&lt;p&gt;Building on our experience as solutions architects, we have put together a comprehensive set of documents for IT practitioners who are planning, designing, and implementing a migration to Google Cloud. At our &lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started"&gt;Migration to Google Cloud&lt;/a&gt; page, you’ll find extensive technical information and advice you need to help plan and execute a successful migration. To help you get started faster, this blog post provides a high-level outline and links into the relevant part of the documentation where you can get more information.&lt;/p&gt;&lt;h3&gt;Getting started with the migration&lt;/h3&gt;&lt;p&gt;Before you start your migration, you should gather some foundational understanding about Google Cloud, your environment, and different migration approaches:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1. &lt;b&gt;Understand the difference between Google Cloud and the current environment.&lt;/b&gt; The source environment could be on-premises or a private hosting environment. These environments have a different operational model compared to a public cloud, from a physical security, networking, power, hardware and virtualization standpoint.&lt;/p&gt;&lt;p&gt;2. &lt;b&gt;Identify the type of workloads that need to be migrated.&lt;/b&gt; We recommend you start your migration by classifying workloads as either legacy, or cloud-native. Legacy workloads were developed without any consideration for cloud environments, with limited support for scaling resources such as disks and compute. As a result, these workloads can be difficult to modify and expensive to run and maintain. When designed following best practices, cloud-native workloads are natively scalable, portable, available, and secure. As a result, cloud-native workloads tend to increase developer productivity and agility, because developers can focus on the actual workloads, rather than spending effort to manage development and runtime environments.&lt;/p&gt;&lt;p&gt;3. &lt;b&gt;Determine your organization’s maturity level for cloud technologies.&lt;/b&gt; When identified early, skill gaps can be addressed as part of the migration process through actions like self-study, training or peer mentorship. You can use Google Cloud’s &lt;a href="https://cloud.google.com/adoption-framework"&gt;Cloud Adoption Framework&lt;/a&gt; to measure your organization’s cloud adoption maturity.&lt;br/&gt;&lt;/p&gt;&lt;p&gt;4. &lt;b&gt;Familiarize yourself with the different types of migration approaches and their tradeoffs&lt;/b&gt;, because different workloads might require different migration approaches. We define three types of migrations:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Lift and shift.&lt;/b&gt; You migrate the workload, applying the least amount of changes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Improve and move.&lt;/b&gt; You modify parts of the workload to adopt cloud-native approaches as part of the migration.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Rip and replace.&lt;/b&gt; You decommission the workload, and write a new workload, adopting a cloud-native approach.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;For more information on migration types refer to the migration guide’s section on &lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started#types_of_migrations"&gt;Types of migration&lt;/a&gt;.&lt;br/&gt;&lt;/p&gt;&lt;h3&gt;The four phases of migration&lt;/h3&gt;&lt;p&gt;Broadly speaking, the migration journey can be captured as a four-phase process: Assess, Plan, Deploy and Optimize. It’s easier to show this linearly, but it’s rarely so straightforward, with these phases often happening in parallel for different workloads.&nbsp;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="migration-to-gcp-getting-started-migration-path-01.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/migration-to-gcp-getting-started-migration.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;h3&gt;Phase 1: Assess the workloads to be migrated&lt;/h3&gt;&lt;p&gt;This phase builds on any pre-work that you’ve done, with a focus on taking an inventory of the workloads that you plan to migrate and their respective dependencies. Things to think about include (but are not limited to) hardware and performance requirements, users, licensing, compliance needs and workload dependencies. Then, map this information into an app catalog that summarizes the information across some key axis questions—for example:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Whether the workload has dependencies, or is a dependency for other workloads&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;How critical the workload is to the business&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;How difficult it is to migrate the workload&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The app catalog will provide you with a high-level view of the amount of effort to migrate all your different workloads. You can also use automated tools such as StratoZone that can scan your existing workloads and provide you with information based on the data gathered. StratoZone not only helps with discovery but can also help you map your instances to matching Google Compute Engine instances. Check out this&nbsp;&lt;a href="https://cloud.google.com/blog/products/cloud-migration/google-cloud-has-acquired-stratozone"&gt;blog post&lt;/a&gt;&nbsp;for an introduction to StratoZone.&nbsp; Additional information on how to conduct discovery is also available in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-assessing-and-discovering-your-workloads#categorizing_your_apps"&gt;Categorizing your apps&lt;/a&gt;&nbsp;section.&nbsp;&lt;/p&gt;&lt;p&gt;To further get a sense of the size of risk or effort, you should conduct a proof of concept (POC) that tests the different use cases and requirements of the workload, with a focus on the more complicated workloads. This aids with getting more information early as well as reducing unknowns.&lt;/p&gt;&lt;p&gt;You should also perform a total cost of ownership (TCO) calculation at this phase, giving the business visibility into what their cloud expenditure will look like as a result of the migration, compared to your existing environment. When moving from an on-prem to a cloud environment, there are often hidden costs that are missed when calculating the costs in the old data center. We list out some of the things to look out for when building this TCO in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-assessing-and-discovering-your-workloads#calculating_total_cost_of_ownership"&gt;Calculating total cost of ownership&lt;/a&gt;&nbsp;section of our guide. Getting the business to understand the shift in cost models and all of the additional benefits gained will be crucial to migration success.&nbsp;&lt;/p&gt;&lt;p&gt;Lastly, you need to decide on which workloads to migrate first. The answer will vary from business to business depending on&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-assessing-and-discovering-your-workloads#choosing_the_apps_to_migrate_first"&gt;many different factors&lt;/a&gt;&nbsp;such as business value of the workload, complexity of migration, and the availability and requirements of the workload. To help guide this decision, it’s a good idea to call a meeting of the subject matter experts of the different workloads and go through a jointly agreed list of factors. Succeeding with the first workload is key to the overall success of your migration journey, as early success yields trust and goodwill, whereas early challenges can sometimes derail entire migration projects.&nbsp;&lt;/p&gt;&lt;h3&gt;Phase 2: Plan the foundation&lt;/h3&gt;&lt;p&gt;The next phase is to plan the foundational pieces of the new cloud environment, which consist of but are not limited to:&lt;/p&gt;&lt;p&gt;1. &lt;b&gt;Establishing user and service identities.&lt;/b&gt; How will users and service accounts be created and managed? You can choose between G Suite or Cloud Identity domains, and optionally integrating with your existing Identity Provider (IdP). Read up on this in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-building-your-foundation#cloud_identity_and_access_management"&gt;Identity and Access management&lt;/a&gt;&nbsp;section.&lt;/p&gt;&lt;p&gt;2. &lt;b&gt;Designing a resource organization hierarchy.&lt;/b&gt; How are the different Google Cloud resources structured hierarchically?&nbsp;&lt;a href="https://cloud.google.com/resource-manager/docs/creating-managing-organization"&gt;Organization nodes,&lt;/a&gt;&nbsp;&lt;a href="https://cloud.google.com/resource-manager/docs/creating-managing-folders"&gt;folders&lt;/a&gt;&nbsp;and&nbsp;&lt;a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects"&gt;projects&lt;/a&gt;&nbsp;provide the building blocks to set up a resource organization hierarchy. A properly designed resource organization simplifies&nbsp;&lt;a href="https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy#inheritance"&gt;access control&lt;/a&gt;&nbsp;and&nbsp;&lt;a href="https://cloud.google.com/billing/docs/how-to/billing-access#relationships-between-resources"&gt;billing management&lt;/a&gt;. Examples of different types of designs are:&lt;/p&gt;&lt;ol&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started#environment-oriented_hierarchy"&gt;&lt;b&gt;Environment oriented hierarchy&lt;/b&gt;&lt;/a&gt;&nbsp;- This design separates out your production, quality assurance and development environments.&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started#function-oriented_hierarchy"&gt;&lt;b&gt;Function orientated hierarchy&lt;/b&gt;&lt;/a&gt;&nbsp;- This design breaks different business functions into their own folders at the top level, and implements an environment-orientated hierarchy beneath it.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started#granular_access-oriented_hierarchy"&gt;&lt;b&gt;Granular orientated hierarchy&lt;/b&gt;&lt;/a&gt;&nbsp;- This design builds on top of the function-orientated hierarchy by adding a business unit organization at the top level.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;p&gt;You can dive deep on this topic in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-building-your-foundation#resource_hierarchy"&gt;resource hierarchy&lt;/a&gt;&nbsp;section.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;3. &lt;b&gt;Defining groups and roles for resource access.&lt;/b&gt; What are the different roles of users who will be accessing your cloud environment? What permissions should these different roles have? You need to create manager roles such as organizational admin, network admin and security admins to manage the cloud resources. It is also a best practice to create specific roles for the different classes of users who will be using the cloud environment, for example developers, testers and site reliability engineers (SREs). All these roles will have a minimum set of permissions associated with them to carry out their tasks. The&nbsp;&lt;a href="https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#groups-and-service-accounts"&gt;Best practices for enterprise organizations&lt;/a&gt;&nbsp;document provides more details on this topic.&lt;br/&gt;&lt;/p&gt;&lt;p&gt;4. &lt;b&gt;Designing your network topology and connectivity.&lt;/b&gt; Into which regions will you deploy your application? Will there be connectivity back into the source environment? How many separate networks will you need to set up? The answers to these questions will feed into how you design your&nbsp;&lt;a href="https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#networking_and_security"&gt;Virtual Private Cloud (VPC)&lt;/a&gt;, which is your private network within Google Cloud. One VPC maps to one standalone network within your cloud environment. A VPC has subnets, firewall rules and routes that allow you to mimic the characteristics of a physical network. It’s important to also ensure you are applying security best practices; you can read about those in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-building-your-foundation#security"&gt;Security&lt;/a&gt;&nbsp;section, as well as in the&nbsp;&lt;a href="https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#secure-apps-and-data"&gt;Secure your apps and data&lt;/a&gt;&nbsp;section of our&nbsp;&lt;a href="https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations"&gt;Best practice for enterprise organizations&lt;/a&gt;&nbsp;guide. Connectivity back to the source environment is also possible using options such as direct interconnect, peering or a VPN. For more information read the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-building-your-foundation#connectivity_and_networking"&gt;Connectivity and networking&lt;/a&gt;&nbsp;section.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Phase 3: Deploy the workloads&lt;/h3&gt;&lt;p&gt;Once the foundation for your migration is in place, the next step is to determine the best approach to deploy your workloads to your cloud environment. You don’t need to take the same approach for all your workloads, however, the more standardized the process is, the more opportunity for cross-team learning and improvement of the deployment process. Example of different deployment approaches are:&lt;/p&gt;&lt;p&gt;1.&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-deploying-your-workloads#deploy_manually"&gt;&lt;b&gt;Fully manual deployments&lt;/b&gt;&lt;/a&gt;. This approach is the simplest and quickest way to get your workload up and running, and can be performed from the&nbsp;&lt;a href="https://console.cloud.google.com/"&gt;Cloud Console&lt;/a&gt;&nbsp;or&nbsp;&lt;a href="https://cloud.google.com/sdk"&gt;Cloud SDK&lt;/a&gt;&nbsp;directly. Although a manual deployment might be all right for some experimentation, we do not recommend this approach for production workload deployments because it is error prone, not repeatable and tends to be poorly documented. If you are currently using manual deployments, the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-automated-containerized-deployments"&gt;Migration from manual deployments to automated, containerized deployments&lt;/a&gt;&nbsp;section will be able to help you improve your process.&nbsp;&lt;/p&gt;&lt;p&gt;For production environments, , a more practical option is to use a service that can automatically replicate the existing workloads in your current environment and deploy it to GCP. Google Cloud offers several such services:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/migrate/compute-engine"&gt;Migrate for Compute Engine&nbsp;&lt;/a&gt;- This allows you to migrate VM-based applications from your existing environment (e.g. VMware, Azure, AWS) to GCP with minimal downtime and risk.&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/migrate/anthos/"&gt;Migrate for Anthos&lt;/a&gt;&nbsp;- Instead of migrating VMs as-is, you can intelligently convert and workloads running in VMs and migrate those workloads into containers in GKE. This often results in a reduction of cost and management.&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/solutions/database-migration"&gt;Database Migration Solutions&lt;/a&gt;&nbsp;- Whether through third parties such as&nbsp;&lt;a href="https://go2.striim.com/migration-service-for-google-cloud" target="_blank"&gt;Striim&lt;/a&gt;, or using native replication support in Google Cloud SQL, there are lots of different techniques to getting your data into Google Cloud.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/vmware-engine"&gt;VMware Engine&lt;/a&gt;&nbsp;- Migrate any existing VMware-based workloads from your on-prem infrastructure without any changes directly to Google Cloud VMware Engine. This allows you to reuse any existing VMware deployment tooling and get started immediately with your migration, and easily add new workloads with the VMware framework within Google Cloud.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-deploying-your-workloads#deploy_with_configuration_management_tools"&gt;&lt;b&gt;Deploy using configuration management tools&lt;/b&gt;&lt;/a&gt;&lt;b&gt;.&lt;/b&gt; Using configuration management (CM) tools such as&nbsp;&lt;a href="https://docs.ansible.com/ansible/latest/scenario_guides/guide_gce.html" target="_blank"&gt;Ansible&lt;/a&gt;,&nbsp;&lt;a href="https://chef.io/" target="_blank"&gt;Chef&lt;/a&gt;&nbsp;or&nbsp;&lt;a href="https://www.puppet.com/" target="_blank"&gt;Puppet&lt;/a&gt;&nbsp;provides a repeatable, automated and controlled way to run your deployment. However, these tools are best suited for provisioning and configuration, and less suitable for workload deployments. This is because the tools require bespoke deployment logic to handle procedures such as zero-downtime deploys, blue-green deployments or rolling updates, and end up becoming more difficult to manage and maintain over the long run.&nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;3.&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-deploying-your-workloads#deploy_by_using_container_orchestration_tools"&gt;&lt;b&gt;Deploy by using container orchestration tools&lt;/b&gt;&lt;/a&gt;&lt;b&gt;.&lt;/b&gt; If your workloads are containerized you can use&nbsp;&lt;a href="https://cloud.google.com/kubernetes-engine"&gt;Google Kubernetes Engine (GKE)&lt;/a&gt;&nbsp;to handle the deployment process. The Kubernetes orchestrator supports many types of&nbsp;&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank"&gt;deployment logic&lt;/a&gt;&nbsp;such as zero-downtime deploys and rolling updates out of the box. Alternatively if your workloads are still on VMs running GCE, Azure or AWS&nbsp;&lt;a href="https://cloud.google.com/migrate/anthos"&gt;Migrate for Anthos&lt;/a&gt;&nbsp;allows you to convert your VMs into containers automatically. This allows you to gain the&nbsp;&lt;a href="https://cloud.google.com/migrate/anthos/docs/anthos-migrate-benefits"&gt;benefit of running on containers&lt;/a&gt;&nbsp;quicker.&nbsp;&lt;/p&gt;&lt;p&gt;4.&nbsp;&lt;b&gt;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-deploying-your-workloads#deploy_automatically"&gt;Deploy automatically&lt;/a&gt;.&lt;/b&gt; An automated deployment process is triggered based on some action that results in a change in the workload and can be built on top of any orchestration tool that can be scripted. Automated deployments allow you to streamline and standardize your deployment process reducing human error.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;You can use tools such as&nbsp;&lt;a href="https://jenkins.io/" target="_blank"&gt;Jenkins&lt;/a&gt;,&nbsp;&lt;a href="https://sonarqube.org/" target="_blank"&gt;SonarQube&lt;/a&gt;,&nbsp;&lt;a href="https://cloud.google.com/cloud-build"&gt;Cloud Build&lt;/a&gt;&nbsp;or&nbsp;&lt;a href="https://spinnaker.io/" target="_blank"&gt;Spinnaker&lt;/a&gt;&nbsp;to build an end-to-end automated deployment pipeline on top of your existing orchestration tools. The key steps of an automated deployment process are:&lt;/p&gt;&lt;ol&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Code review.&lt;/b&gt; Every change to your codebase should be reviewed by a peer to ensure the quality of the change before merging it into the codebase.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Continuous integration (CI).&lt;/b&gt; Once merged, the CI tool runs all existing tests against the new version for the codebase and ensures that no tests fail. Only then does it mark the build as successful.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Artifact production.&lt;/b&gt; For every successful build an artifact is produced. A container is an example of an artifact. Tests can also be run by using tools such as&nbsp;&lt;a href="https://serverspec.org/" target="_blank"&gt;Serverspec&lt;/a&gt;&nbsp;to ensure that the artifacts are working well.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Continuous deployment (CD).&lt;/b&gt;A successful artifact is then deployed into your development or quality assurance cloud environment, after which another set of functional tests could be run against the deployment to ensure that its running well. Once those tests pass, the deployment can then be deployed to your production environment, either automatically, or after being manually triggered by an operator.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;p&gt;5.&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-deploying-your-workloads#deploy_by_applying_the_infrastructure_as_code_pattern"&gt;&lt;b&gt;Deploy by applying the infrastructure-as-code pattern&lt;/b&gt;&lt;/a&gt;&lt;b&gt;.&lt;/b&gt; The idea behind infrastructure as code is to treat configuring and provisioning your cloud resources in the same way you treat the source code for your workloads. Similar to how new versions of workloads are deployed by going through a series of automated steps and tests, any changes to the infrastructure configuration also go through a series of steps that involve testing before being deployed to the target cloud environment. This is our recommended best practice as it provides repeatability and traceability, which improve overall deployment velocity. This process can be implemented using tools such as&nbsp;&lt;a href="https://www.terraform.io/" target="_blank"&gt;Terraform&lt;/a&gt;&nbsp;and managed services such as a&nbsp;&lt;a href="https://cloud.google.com/deployment-manager"&gt;Deployment Manager&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;Phase 4: Optimize your environment&lt;/h3&gt;&lt;p&gt;Once a basic deployment of your workloads is running and tested in your new Google Cloud environment, you can start to improve on this foundation. This includes critical pieces that should be completed before cutting over live traffic, for example training your team on new cloud operational playbooks as well as ensuring that&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-building-your-foundation#monitoring_and_alerting"&gt;logging, monitoring and alerting&lt;/a&gt;&nbsp;for these workloads are in place.&lt;/p&gt;&lt;p&gt;Other aspects that you can optimize once the workload is serving production traffic include:&nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Cost optimization with autoscaling&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Moving to managed workloads to reduce operational overhead&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Automating the deployment process&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Read up on how best to approach this in the&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-google-cloud-optimizing-your-environment"&gt;Optimizing your environment&lt;/a&gt;&nbsp;section.&nbsp;&lt;/p&gt;&lt;h3&gt;Read on to ensure a successful cloud migration&lt;/h3&gt;&lt;p&gt;A large migration can be daunting for the most ambitious of teams. But with the right methodology, planning, and testing before deployment, you can break the problem down into smaller, more manageable steps. Our&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started"&gt;Migration to Google Cloud&lt;/a&gt;&nbsp;solution guide covers the above in more detail, and also provides additional resources, like our ‘&lt;a href="https://cloud.google.com/solutions/migration-to-gcp-getting-started#finding_help"&gt;Finding Help&lt;/a&gt;’ section, that you can use to help start migrating your workloads to the cloud.&nbsp;&nbsp;&lt;/p&gt;&lt;p&gt;If you require more assistance from professionals who have a track record of successful migrations, the&nbsp;&lt;a href="https://cloud.google.com/consulting"&gt;Google Cloud Professional Services Organization&lt;/a&gt;&nbsp;offers consulting services directly or via a host of&nbsp;&lt;a href="https://cloud.google.com/solutions/migration-center#section-5"&gt;partners&lt;/a&gt;&nbsp;with a wide range of specialties. Just reach out and we can help you get on your way!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Mon, 21 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/cloud-migration/guide-to-all-google-cloud-migration-guides/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Cloud Migration
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_CloudMigration_B_L8be8Js.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Cloud migration: What you need to know (and where to find it)</title>
    <description>
     Google Cloud offers a rich set of solutions and documentation to help guide your cloud migration. Here’s where to find what you need.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_CloudMigration_B_L8be8Js.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/cloud-migration/guide-to-all-google-cloud-migration-guides/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Mohan Krishnan
    </name>
    <title>Solutions Architect</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>gVisor: Protecting GKE and serverless users in the real world</title>
   <link>
    https://cloud.google.com/blog/products/containers-kubernetes/how-gvisor-protects-google-cloud-services-from-cve-2020-14386/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Security is a top priority for Google Cloud, and we protect our customers through how we design &lt;a href="https://cloud.google.com/security/"&gt;our infrastructure, our services, and how we work&lt;/a&gt;. Googlers created some of the fundamental components of containers, like cgroups, and we were an early adopter of containers for our internal systems. We realized we needed a way to increase the security of this technology. This led to the development of &lt;a href="https://gvisor.dev/" target="_blank"&gt;gVisor&lt;/a&gt;, a container security sandbox that we have since open sourced and integrated into multiple Google Cloud products. When a &lt;a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14386" target="_blank"&gt;recent Linux kernel vulnerability was disclosed,&lt;/a&gt; users of these products were not affected because they were protected by gVisor.&lt;/p&gt;&lt;h3&gt;The latest container escape&lt;/h3&gt;&lt;p&gt;While auditing the 5.7 kernel release, an employee of Palo Alto Networks recently discovered a &lt;a href="https://cloud.google.com/support/bulletins#gcp-2020-012"&gt;Linux kernel vulnerability&lt;/a&gt;, which has the potential to be used for “container escapes.” Containers share the same host kernel, which is one of the properties that allow them to be densely packed and highly portable. A container escape refers to a category of vulnerabilities seen in containerized systems where—typically through privilege escalation—an unauthorized user gains access to the host system, giving the attacker an entrypoint for whatever they’d like to do next, for example data exfiltration or cryptomining. (You can learn more container security fundamentals in this ebook, &lt;a href="https://inthecloud.withgoogle.com/anthos-security/Dl-cd.html" target="_blank"&gt;“Why Container Security Matters to Your Business.”&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;This vulnerability, &lt;a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14386" target="_blank"&gt;CVE-2020-14386&lt;/a&gt;, uses the CAP_NET_RAW capability of the Linux kernel to cause memory corruption, allowing an attacker to gain root access when they should not have. In Docker, the most commonly used container format with Kubernetes, the CAP_NET_RAW capability is enabled by default. This means that “out of the box,” your Kubernetes deployment—or the infrastructure of your serverless applications—could be compromised by this recent vulnerability. Even if your security team has told you to disable some of these default capabilities, CAP_NET_RAW is commonly used by networking tools such as ping and tcpdump, and may have been re-enabled for troubleshooting purposes!&nbsp;&lt;/p&gt;&lt;h3&gt;Mitigating CVE-2020-14386 with gVisor&lt;/h3&gt;&lt;p&gt;If you saw the &lt;a href="https://cloud.google.com/kubernetes-engine/docs/security-bulletins#gcp-2020-012"&gt;Google Kubernetes Engine security bulletin&lt;/a&gt;, you may have noticed a line you hadn’t seen before: &lt;b&gt;“Pods running in&lt;/b&gt;&lt;a href="https://cloud.google.com/kubernetes-engine/docs/concepts/sandbox-pods"&gt;&lt;b&gt;GKE Sandbox&lt;/b&gt;&lt;/a&gt;&lt;b&gt;are not able to leverage this vulnerability.” If you’re a user of &lt;a href="https://cloud.google.com/run"&gt;Cloud Run&lt;/a&gt;, &lt;a href="https://cloud.google.com/functions"&gt;Cloud Functions&lt;/a&gt; or&lt;/b&gt;&lt;a href="https://cloud.google.com/appengine"&gt;&lt;b&gt;App Engine standard environment&lt;/b&gt;&lt;/a&gt;&lt;b&gt;, you are protected from this vulnerability as well,&lt;/b&gt; and will not have experienced any service disruptions or been issued patching instructions. All these platforms utilize &lt;a href="https://gvisor.dev/" target="_blank"&gt;gVisor&lt;/a&gt; to securely “sandbox” workloads, which protected users from this vulnerability.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="Mitigating CVE-2020-14386 with gVisor.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Mitigating_CVE-2020-14386_with_gVisor.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;gVisor takes inspiration from a &lt;a href="https://cloud.google.com/security/infrastructure/design/resources/google_infrastructure_whitepaper_fa.pdf"&gt;common principle in security&lt;/a&gt; that states that you should have multiple distinct layers of protection, and that those layers should not be susceptible to the same kinds of compromises. Containers rely on namespaces and cgroups as their primary layer of isolation; gVisor then introduces a second layer by handling syscalls through the Sentry (a kernel written in &lt;a href="https://golang.org/" target="_blank"&gt;Go&lt;/a&gt;) that emulates Linux in userspace. This significantly reduces the number of syscalls allowed to reach the host kernel, and thereby reduces the attack surface. In addition to the isolation provided by the Sentry, gVisor uses a specific TCP/IP stack, Netstack, for yet another layer of protection.&nbsp;&lt;/p&gt;&lt;p&gt;In this case, the vulnerability is first hindered by having CAP_NET_RAW disabled by default. However, even if enabled, the vulnerability does not exist for gVisor: the problematic C code in Linux is not used in the gVisor networking stack. More importantly, this &lt;i&gt;kind&lt;/i&gt; of attack—the exploitation of out-of-bounds array writes—is much less likely in the Sentry and its networking stack, thanks to the use of Go. You can read a technical deep dive on how gVisor mitigates this vulnerability &lt;a href="https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability/" target="_blank"&gt;here&lt;/a&gt;.&lt;br/&gt;&lt;/p&gt;&lt;h3&gt;Making security a priority&lt;/h3&gt;&lt;p&gt;Taking a step back, Linux is a fundamentally complex and evolving system, and security is thus an ongoing challenge. As a professor at UC Berkeley in 1996, I first worked on &lt;a href="https://www.usenix.org/legacy/publications/library/proceedings/sec96/full_papers/goldberg/goldberg.pdf" target="_blank"&gt;intercepting syscalls to improve Linux security&lt;/a&gt; and it remains an important approach. The &lt;a href="https://web.stanford.edu/group/mast/cgi-bin/drupal/system/files/2012.dune_.osdi_.pdf" target="_blank"&gt;Dune system&lt;/a&gt; later showed how to use virtualization hardware to intercept syscalls, leading essentially to a “virtual process” rather than a “virtual machine.” However, as with the earlier work, it then forwarded calls to the normal Linux kernel, and attackers could thus still reach the underlying kernel.&nbsp;&lt;/p&gt;&lt;p&gt;In contrast, gVisor actually implements the Linux syscalls directly in Go. Although it still makes some use of the underlying kernel, gVisor is never a direct passthrough of adversary-controlled data. In some sense gVisor is really a safe (small) version of Linux. Because Go is type- and memory-safe, huge classes of classic Linux problems, such as buffer overflows and out-of-bounds array writes, just disappear. The implementation is also orders-of-magnitude smaller, which further improves security.&lt;/p&gt;&lt;p&gt;However, the gVisor approach introduces tradeoffs, and there are currently downsides to picking this more secure path. The first downside is that gVisor will always have semantic differences from “real” Linux, although it is close enough to execute the vast majority of applications in practice. The rise of containers helps on this front, as it has led to less interest in distro specifics and more demand for portability. And Linux has done an incredible job on API stability, so the semantics are stable and well defined.&lt;/p&gt;&lt;p&gt;The second downside is that intercepting syscalls has performance overhead for workloads that are I/O intensive (based more on the number of calls than the amount of data). This will of course improve over time, but it is a factor for some applications. Many applications should prefer stronger security, but clearly not all do.&lt;/p&gt;&lt;p&gt;My hope is that Linux and the security community can get to a place where the user doesn’t have to sacrifice performance for security. To make this a reality, open-source communities are going to have to prioritize security in upstream design in the kernel and other core open-source projects. Efforts like the &lt;a href="https://openssf.org/" target="_blank"&gt;Open Source Security Foundation&lt;/a&gt; make me hopeful that we can solve this together.&lt;/p&gt;&lt;h3&gt;Protecting your cloud-native applications&nbsp;&lt;/h3&gt;&lt;p&gt;In the meantime, we’re committed to making the “secure” thing to do, the easy thing to do. At Google Cloud, we offer you the ability to use gVisor for your &lt;a href="http://cloud.google.com/kubernetes-engine"&gt;Google Kubernetes Engine&lt;/a&gt; (GKE) cluster with &lt;a href="https://cloud.google.com/kubernetes-engine/docs/concepts/sandbox-pods"&gt;GKE Sandbox&lt;/a&gt;, and have built gVisor into the infrastructure that runs our serverless services &lt;a href="https://cloud.google.com/appengine"&gt;App Engine&lt;/a&gt;, &lt;a href="https://cloud.google.com/run"&gt;Cloud Run&lt;/a&gt; and &lt;a href="https://cloud.google.com/functions"&gt;Cloud Functions&lt;/a&gt;. In the case of GKE, added layers of defense are only clicks away, and for Cloud Run and App Engine, users get these added layers of protection without having to do anything!&lt;/p&gt;&lt;p&gt;If you’re running on GKE Sandbox, your pods are not affected by this vulnerability. However, as part of your security best practices, you should still upgrade to protect system containers that run on all nodes. If you are not a GKE Sandbox user, your first step is to upgrade your control plane and nodes to one of the versions listed in the &lt;a href="https://cloud.google.com/kubernetes-engine/docs/security-bulletins#gcp-2020-012"&gt;GKE security bulletin&lt;/a&gt;, and then follow the recommendations for removing CAP_NET_RAW through &lt;a href="https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller"&gt;Policy Controller&lt;/a&gt;, &lt;a href="https://github.com/open-policy-agent/gatekeeper" target="_blank"&gt;Gatekeeper&lt;/a&gt;, or &lt;a href="https://cloud.google.com/kubernetes-engine/docs/how-to/pod-security-policies"&gt;PodSecurityPolicy&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Your next step is to enable GKE Sandbox. As a managed service, GKE Sandbox handles the internals of running open-source &lt;a href="https://gvisor.dev/" target="_blank"&gt;gVisor&lt;/a&gt; for you; there are no changes needed to your applications, and adding defense-in-depth to your pods is just a matter of a few clicks.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="gVisor security.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/gVisor_security.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Whether your applications run in containers or serverlessly, get started with &lt;a href="https://cloud.google.com/kubernetes-engine"&gt;GKE&lt;/a&gt; or &lt;a href="https://cloud.google.com/serverless"&gt;Google Cloud’s serverless solutions&lt;/a&gt; to get the security benefits of gVisor.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/gcp/open-sourcing-gvisor-a-sandboxed-container-runtime/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/cloud_sandbox.max-500x500.png')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Open-sourcing gVisor, a sandboxed container runtime&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Containers have revolutionized how we develop, package, and deploy applications. However, the system surface exposed to containers is bro...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Fri, 18 Sep 2020 17:30:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/containers-kubernetes/how-gvisor-protects-google-cloud-services-from-cve-2020-14386/
   </guid>
   <category>
    Identity &amp; Security
   </category>
   <category>
    Open Source
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Containers &amp; Kubernetes
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Security_BlogHeader_B_.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>gVisor: Protecting GKE and serverless users in the real world</title>
    <description>
     Many Google Cloud compute platforms are based on gVisor, and thus impervious to a recently discovered container vulnerability.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Security_BlogHeader_B_.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/containers-kubernetes/how-gvisor-protects-google-cloud-services-from-cve-2020-14386/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Eric Brewer
    </name>
    <title>VP Infrastructure and Fellow, Google Cloud</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Tips and tricks for using new RegEx support in Cloud Logging</title>
   <link>
    https://cloud.google.com/blog/products/management-tools/cloud-logging-gets-regular-expression-support/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;One of the most frequent questions customers ask is “how do I find &lt;i&gt;this&lt;/i&gt; in my logs?”—often followed by a request to use &lt;a href="https://en.wikipedia.org/wiki/Regular_expression" target="_blank"&gt;regular expressions&lt;/a&gt; in addition to our &lt;a href="https://cloud.google.com/logging/docs/view/logging-query-language"&gt;logging query language&lt;/a&gt;. We’re delighted to announce that we recently added support for regular expressions to our query language — now you can search through your logs using the same powerful language selectors as you use in your tooling and software!&nbsp;&lt;/p&gt;&lt;p&gt;Even with regex support, &lt;a href="https://cloud.google.com/logging/docs/view/query-library"&gt;common queries&lt;/a&gt; and &lt;a href="https://cloud.google.com/logging/docs/view/logging-query-language"&gt;helpful examples in our docs&lt;/a&gt;, searching petabytes of structured or unstructured log data efficiently is an art, and sometimes there’s no substitute for talking to an expert. We asked Dan Jacques, a software engineering lead on logging who led the effort to add regular expressions to the logging query language, to share some background on how logging works and tips and tricks for exploring your logs.&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;Can you tell me a little bit about Cloud Logging’s storage and query backend?&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Cloud Logging stores log data in a massive internal time-series database. It's optimized for handling time-stamped data like logs, which is one of the reasons you don’t need to swap out old logs data to cold storage like some other logging tools. This is the same database software that powers internal Google service logs and monitoring. The database is designed with scalability in mind and processes over 2.5 EB (exabytes!) of logs per month, which thousands of Googlers and Google Cloud customers query to do their jobs every day...&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;Can you tell me about your experience adding support for regular expressions into the logging query language?&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;I used Google Cloud Platform and Cloud Logging as a Googler quite a bit prior to joining the team, and had experienced a lack of regular expression support as a feature gap. Championing regular expression support was high on my list of things to do. Early this year I got a chance to scope out what it would require. Shortly after, my team and I got to work implementing regular expression support.&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;As someone who has to troubleshoot issues for customers, can you share some tips and best practices for making logging queries perform as well as possible?&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Cloud Logging provides a very flexible, largely free-form logging structure, and a very powerful and forgiving query language. There are clear benefits to this approach: log data from a large variety of services and sources fit into our schema, and you can issue queries using a simple and readable query notation. However, the downside of being general purpose is that it's challenging to optimize for every data and query pattern. As a general guide, you can improve performance by narrowing the scope of your queries as much as possible, which in turn narrows the amount of data we have to search. Here are some specific ideas for narrowing scope and improving performance:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Add "resource type" and "log name" fields to your query whenever you can.&lt;/b&gt; These fields are indexed in such a way that make them particularly effective at improving performance. Even if the rest of your query already only selects records from a certain log/resource, adding these constraints informs our system not to spend time looking elsewhere. The new Field Explorer feature can help drill down into specific resources.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Original search: &lt;code&gt;"CONNECTING"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Specific search:&lt;/p&gt;&lt;p&gt;&lt;code&gt;LOG_ID(stdout)&lt;/code&gt;&nbsp;&lt;br/&gt;&lt;code&gt;resource.type="k8s_container"&lt;/code&gt;&lt;br/&gt;&lt;code&gt;resource.labels.location="us-central1-a"&lt;br/&gt;&lt;/code&gt;&lt;code&gt;resource.labels.cluster_name="test"&lt;br/&gt;&lt;/code&gt;&lt;code&gt;resource.labels.namespace_name="istio-system"&lt;br/&gt;&lt;/code&gt;&lt;code&gt;"CONNECTING"&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Choose as narrow a time range as possible.&lt;/b&gt;&nbsp;Let’s suppose you’re looking for a VM that was deleted about a year ago. Since our storage system is optimized for time, limiting your time range to a month will really help with performance. You can select the timestamp through the UI or by adding it to the search explicitly.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="choose time range.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/choose_time_range.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Pro tip: you can paste a timestamp like the one below directly into the field for custom time.&nbsp;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Original search:&nbsp;&lt;code&gt;"CONNECTING"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Specific search:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;timestamp&amp;gt;="2019-08-05T18:34:19.856588299Z"&lt;/code&gt;&lt;br/&gt;&lt;code&gt;timestamp&amp;lt;="2019-09-05T18:34:19.856588299Z"&lt;/code&gt;&lt;br/&gt;&lt;code&gt;"CONNECTING"&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Put highly-queried data into&lt;/b&gt; &lt;a href="https://cloud.google.com/logging/docs/view/advanced-queries#indexed-fields"&gt;&lt;b&gt;indexed fields&lt;/b&gt;&lt;/a&gt;. You can use the Cloud Logging agent to &lt;a href="https://cloud.google.com/logging/docs/agent/configuration#label-setup"&gt;route log data to indexed fields&lt;/a&gt; for improved performance, for example. Placing indexed data in the "labels" LogEntry field will generally yield faster look-ups.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Restrict your queries to a specific field&lt;/b&gt;. If you know that the data you’re looking for is in a specific field, &lt;a href="https://cloud.google.com/logging/docs/view/advanced-queries#comparisons"&gt;restrict the query&lt;/a&gt; to that field rather than using the less efficient &lt;a href="https://cloud.google.com/logging/docs/view/advanced-queries#global_restrictions"&gt;global restriction&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Original search: &lt;code&gt;"CONNECTING"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Specific search:&nbsp;&lt;/p&gt;&lt;p&gt;&lt;code&gt;textPayload =~ "CONNECTING"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;Can you tell us more about using regular expressions in Cloud Logging?&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Our filter language is very good at finding text, or values expressed as text, in some cases to the point of oversimplification at the expense of specificity. Prior to regular expressions, if you wanted to search for any sort of pattern complexity, you had to build a similitude of that complexity out of conjunctive and disjunctive terms, often leading to over-querying log entries and underperforming queries.&nbsp;&nbsp;&lt;/p&gt;&lt;p&gt;Now, with support for regular expressions, you can perform a case-sensitive search, match complex patterns, or even substring search for a single "*" character.&lt;/p&gt;&lt;p&gt;The RE2 syntax we use for regular expressions is a familiar, well-documented, and performant regular expression language. Offering it to users as a query option allows users to naturally and performantly express exactly the log data that they are searching for.&lt;/p&gt;&lt;p&gt;For example, previously if you wanted to search for a text payload beginning with "User" and ending with either "Logged In" or "Logged Out", you would have to use a substring expression like:&nbsp;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(textPayload:User AND (textPayload:"Logged In" OR textPayload:"Logged Out"))&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Something like this deviates significantly from the actual intended query:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;There is no ordering in substring matching, so "I have Logged In a User" would match the filter's constraints.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Each term executes independently, so this executes up to three matches per candidate log entry internally, costing additional matching time.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Substring matches are case-insensitive. There is no way to exclude e.g., "logged in".&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;But with a regular expression, you can execute:&lt;/p&gt;&lt;p&gt;&lt;code&gt;textPayload =~ "^User.*Logged (In|Out)$"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This is simpler and selects exactly what you're looking for.&lt;/p&gt;&lt;p&gt;Since we dogfood our own tools and the Cloud Logging team uses Cloud Logging for troubleshooting, our team has found it really useful and I hope it's as useful to our customers!&lt;/p&gt;&lt;p&gt;&lt;b&gt;Ready to get started with Cloud Logging?&nbsp;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Keep in mind these tips from Dan that will speed up your searches:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Add a resource type and log name to your query whenever possible,&nbsp;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Keep your selected time range as narrow as possible.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If you know that what you’re looking for is part of a specific field, search on that field rather than using a global search.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use regex to perform case sensitive searches or advanced pattern matching against string fields. Substring and global search are always case insensitive.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Add highly-queried data fields into the indexed "labels" field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Head over to the&nbsp;&lt;a href="https://console.cloud.google.com/logs/query"&gt;Logs Viewer&lt;/a&gt;&nbsp;to try out these tips as well as the new regex support.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/management-tools/cloud-logging-now-offers-suggested-queries/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/G-Management-banner-05.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Analyze your logs quickly with suggested queries beta in Cloud Logging&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;New suggested queries in Cloud Logging help highlight important logs, so you can troubleshoot issues faster.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 17 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/management-tools/cloud-logging-gets-regular-expression-support/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Management Tools
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/004-GBH-ManagementTools.max-600x600.png" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Tips and tricks for using new RegEx support in Cloud Logging</title>
    <description>
     Learn how to optimize your Cloud Logging queries to find the logs you need, faster.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/004-GBH-ManagementTools.max-600x600.png
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/management-tools/cloud-logging-gets-regular-expression-support/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Dan Jacques
    </name>
    <title>Software Engineer</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Mary Koes
    </name>
    <title>Product Manager, Google Cloud</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Data warehouse migration tips: preparation and discovery</title>
   <link>
    https://cloud.google.com/blog/products/data-analytics/how-to-prepare-for-a-data-warehouse-migration-with-google-cloud/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Data warehouses are at the heart of an organization’s decision making process, which is why many businesses are moving away from the siloed approach of traditional data warehouses to a modern data warehouse that provides advanced capabilities to meet changing requirements. At Google Cloud, we often work with customers on data warehouse migration projects, including helping &lt;a href="https://youtu.be/jx9NozDp2XY?t=983" target="_blank"&gt;HSBC&lt;/a&gt; migrate to &lt;a href="https://cloud.google.com/bigquery"&gt;BigQuery&lt;/a&gt;, reducing more than 600 reports and several related applications and data pipelines. We’ve even assembled &lt;a href="https://cloud.google.com/solutions/migration/dw2bq/dw-bq-migration-overview"&gt;a migration framework&lt;/a&gt; that highlights how to prepare for each phase of migration to reduce risk and define a clear business case up front to get support from internal stakeholders.&nbsp;&lt;/p&gt;&lt;p&gt;While we offer a &lt;a href="https://cloud.google.com/solutions/migration/dw2bq/dw-bq-migration-overview"&gt;data management maturity model&lt;/a&gt;, we still receive questions, specifically around how to prepare for migration. In this post, we’ll explore a few important questions that come up during the initial preparation and discovery phases, including the impact of modernizing a data warehouse in real life and how you can better prepare for and plan your migration to a modern data warehouse.&lt;/p&gt;&lt;h3&gt;Tackling the preparation phase&lt;/h3&gt;&lt;p&gt;An enterprise data warehouse has many stakeholders with a wide range of use cases, so it’s important to identify and involve the key stakeholders early in the process to make sure they’re aligned with the strategic goals. They can also help identify gaps and provide insight on potential use cases and requirements, which can help prioritize the highest impact use cases and identify associated risks. These decisions can then be approved and aligned with business metrics, which usually revolve around three main components:&lt;/p&gt;&lt;p&gt;&lt;b&gt;People.&lt;/b&gt; To make sure you’re getting input and buy-in for your migration, start with aligning leadership and business owners. Then, explore the skills of the project team and end users. You might identify and interview each functional group within the team by conducting workshops, hackathons, and brainstorming sessions. Remember while discussing issues to consider how to secure owner sign-off by setting success criteria and KPIs, such as:&nbsp;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Time saved&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Time to create new reports&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reporting usage increase&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Talent acquired through innovation&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Technology.&lt;/b&gt; By understanding the current technical landscape and classifying existing solutions to identify independent workloads, you can more easily separate upstream and downstream applications to further drill down into their dependency on specific use cases. For example, you can cluster and isolate different ETL applications/pipelines based on different use cases or source-systems being migrated to reduce the scope as well as underlying risks. Similarly, you can couple them with upstream applications and make a migration plan which moves dependent applications and related data pipelines together.&lt;/p&gt;&lt;p&gt;In addition to understanding current migration technologies, it’s key that you are clear on what you are migrating. This includes identifying appropriate data sources with an understanding of your data velocity, data regionality, and licensing, as well as identifying business intelligence (BI) systems with current reporting requirements and desired modernizations during the migration. For example, you might want to move that daily report about sales to a real-time dashboard. You might also want to decide if any upstream or downstream applications should be replaced by a cloud-native application and could be driven by KPIs below:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;TCO of new solution vs. functionality gains&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Performance improvements and scalability&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lower manageability&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Risk of lock-in vs. using open source&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Process&lt;/b&gt;. By discussing your process options, you can uncover dependencies between existing components and data access and governance requirements, as well as the ability to split migration components. For example, you should evaluate license expiration dependencies before defining any migration deadlines. Processes should be established to make effective decisions during migration and ensure optimal progress inline, using KPIs such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Risk of data leakage and misuse&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Revenue growth per channel&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;New services launched vs. cost of launching them&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Adoption of ML-driven analytics&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;A strong understanding of the processes you intend to put in place can open up new opportunities for growth. For example, a well-known ecommerce retailer wanted to drive product and services personalization. Their existing data warehouse environment did not provide predictive analytics capabilities and required investments in new technology. &lt;a href="https://cloud.google.com/bigquery-ml/docs/bigqueryml-intro"&gt;BigQuery ML&lt;/a&gt; allowed them to be agile and apply predictive analytics, unlocking increased lifetime value, optimized marketing investment, improved customer satisfaction, and increased market share.&lt;/p&gt;&lt;h3&gt;Entering the discovery phase&lt;/h3&gt;&lt;p&gt;The discovery process is mainly concerned with two areas: business requirements and technical information.&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Understanding business requirements&lt;/b&gt;&lt;/p&gt;&lt;p&gt;The discovery process of a data warehouse migration starts with understanding business requirements and usually has a number of business drivers. Replacing legacy systems has implications in many fronts, ranging from new team skill set requirements to managing ongoing license and operational costs. For example, upgrading your current system might require all of your company’s data analysts to be re-trained, as well as new additional licenses to be purchased. Quantifying these requirements, and associating them with costs, will allow you to make a pragmatic, fair assessment of the migration process.&nbsp;&lt;/p&gt;&lt;p&gt;On the other hand, proposing and validating potential improvement gains by identifying gaps in the current solution will add value. This can be done by defining an approach to enhance and augment the existing tools with new solutions. For example, for a retailer, the ability to deliver new real-time reporting will increase revenue, since it provides significant improvements in forecasting and reduced shelf-outs.&lt;/p&gt;&lt;p&gt;This retailer realized that shelf-outs were costing them millions in lost sales. They wanted to find an effective solution to predict inventory needs accurately. Their legacy data warehouse environment had reached its performance peak, so they wanted a cloud offering like BigQuery to help them analyze massive data workloads quickly. As a result of migrating, they were able to&lt;a href="https://youtu.be/ppHL_suopiI?t=1879" target="_blank"&gt;stream terabytes of data&lt;/a&gt; in real time and quickly optimize shelf availability to save on costs and get other benefits like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Incremental revenue increase with reduced shelf-outs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2x accuracy vs. previous predictive model&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Business challenges that were previously perceived as too difficult to solve can be identified as new opportunities by re-examining them using new technologies. For example, the ability to store and process more granular data can aid organizations in creating more targeted solutions. A retailer may look into seasonality and gauge customer behavior if Christmas Day falls on a Monday versus another day of the week. This can only be achieved with the ability to store and analyze increased amounts of data spanning across many years.&lt;/p&gt;&lt;p&gt;Last but not least: Educating your users is key to any technology modernization project. In addition to learning paths defined above this can be done by defining eLearning plans for self study. In addition, staff should have time to be hands-on and start using the new system to learn by doing. You can also identify external specialized partners and internal champions early on to help bridge that gap.&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Technical information gathering&lt;/b&gt;&lt;/p&gt;&lt;p&gt;In order to identify the execution strategy, you’ll want to answer the following question: Will your migration process focus on a solution layer or an end-to-end lift-and-shift approach? Going through some of the points below can make this decision simpler:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Identify data sources for up and downstream applications&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Identify datasets, tables and schemas relevant for use cases&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Outline ETL/ELT tools and frameworks&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Define data quality and data governance solutions&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Identify &lt;a href="https://cloud.google.com/iam"&gt;Identity and Access Management (IAM)&lt;/a&gt; solutions&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Outline BI and reporting tools&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Further, it is important to identify some of the functional requirements before making a decision around buy or build. Are there any out-of-the-box solutions available in the market that meet the requirements, or will you need a custom-built solution to meet the challenges you’ve identified? Make sure you know whether this project is core to your business, and would add value,&nbsp; before deciding on the approach.&lt;/p&gt;&lt;p&gt;Once you’ve concluded the preparation and discovery phase, you’ll have some solid guidance on which components you’ll be replacing or refactoring with a move to a cloud data warehouse.&nbsp;&nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Visit our website to &lt;a href="https://cloud.google.com/bigquery"&gt;learn more about BigQuery&lt;/a&gt;.&lt;/i&gt;&lt;/p&gt;&lt;hr/&gt;&lt;i&gt;&lt;sup&gt;Thanks to Ksenia Nekrasova for contributions to this post.&lt;/sup&gt;&lt;/i&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/data-analytics/data-warehouse-migration-challenges-and-how-to-meet-them/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Data warehouse migration challenges and how to meet them&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Moving your legacy data warehouse to cloud can bring challenges. Here are some tips to make the data warehouse cloud migration process ea...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 17 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/data-analytics/how-to-prepare-for-a-data-warehouse-migration-with-google-cloud/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    BigQuery
   </category>
   <category>
    Data Analytics
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Data_Analytics_5I5zzaa.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Data warehouse migration tips: preparation and discovery</title>
    <description>
     In this post, we’ll explore a few important questions that come up during the initial preparation and discovery phase for data warehouse migration.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Data_Analytics_5I5zzaa.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/data-analytics/how-to-prepare-for-a-data-warehouse-migration-with-google-cloud/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Usman Ali
    </name>
    <title>EMEA Solution Lead, Data Analytics</title>
    <department></department>
    <company></company>
   </author>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Firat Tekiner
    </name>
    <title>EMEA Solution Lead, Data Analytics</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Now, setting up continuous deployment for Cloud Run is a snap</title>
   <link>
    https://cloud.google.com/blog/products/application-development/cloud-run-integrates-with-continuous-deployment/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Deploying code to production directly from your dev machine can lead to unforeseen issues: the code might have local changes, the process is manual and error prone, and tests can be bypassed. And later on, it makes it impossible to understand what actual code is running in production. A best practice for avoiding these hardships is to continuously deploy your code when changes are pushed to a branch of your source repository.&lt;/p&gt;&lt;p&gt;As &lt;a href="https://cloud.google.com/blog/topics/google-cloud-next/developer-productivity-announcements-at-next20-onair"&gt;we announced at Google Cloud Next ‘20: OnAir&lt;/a&gt;, Cloud Run now allows you to set up continuous deployment in just a few clicks: From the Cloud Run user interface, you can now easily connect to your Git repository and set up continuous deployment to automatically build and deploy your code to your Cloud Run and Cloud Run or Anthos services. This feature is available for both new and existing services.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-video"&gt;&lt;div class="article-module article-video "&gt;&lt;figure&gt;&lt;a class="h-c-video h-c-video--marquee" data-glue-modal-disabled-on-mobile="true" data-glue-modal-trigger="uni-modal-k_guwXJFmUI-" href="https://youtube.com/watch?v=k_guwXJFmUI"&gt;&lt;img alt="Cloud Run now allows you to set up continuous deployment in just a few clicks: From the Cloud Run user interface, you can now easily connect to your Git repository and set up continuous deployment to automatically build and deploy your code to your Cloud Run and Cloud Run or Anthos services." src="//img.youtube.com/vi/k_guwXJFmUI/maxresdefault.jpg"/&gt;&lt;svg class="h-c-video__play h-c-icon h-c-icon--color-white" role="img"&gt;&lt;use xlink:href="#mi-youtube-icon"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div class="h-c-modal--video" data-glue-modal="uni-modal-k_guwXJFmUI-" data-glue-modal-close-label="Close Dialog"&gt;&lt;a class="glue-yt-video" data-glue-yt-video-autoplay="true" data-glue-yt-video-height="99%" data-glue-yt-video-vid="k_guwXJFmUI" data-glue-yt-video-width="100%" href="https://youtube.com/watch?v=k_guwXJFmUI" ng-cloak=""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;You can select any repository that includes a Dockerfile or code written in Go, Node.js, Java, Python and .NET. Under the hood, the continuous deployment setup process configures a Cloud Build trigger that builds the code into a container using Docker or &lt;a href="https://github.com/GoogleCloudPlatform/buildpacks" target="_blank"&gt;Google Cloud Buildpacks&lt;/a&gt;, pushes it to Google Container Registry and deploys it to your Cloud Run service. You can later customize this by adding steps to the Cloud Build trigger configuration, for example adding unit or integration tests before deploying.&lt;/p&gt;&lt;p&gt;By default, your code is automatically built and deployed to a new Cloud Run revision, but you can decide if it should receive 100% of the incoming traffic immediately or not, and later gradually migrate traffic using the newly added &lt;a href="https://cloud.google.com/blog/products/serverless/cloud-run-now-supports-gradual-rollouts-and-rollbacks"&gt;traffic controls&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;With Continuous Deployment set up, the Cloud Run service detail page shows relevant in-context information:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A link to the exact commit in the Git repository that was used for this deployment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A link to the build logs and the build trigger that created this revision / container.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A quick preview of the health of the latest builds.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="cloud run gcp console.jpg" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/cloud_run_gcp_console.max-1000x1000.jpg"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Pushing your code directly to production was never a good idea. Now, Cloud Run makes it easy for you to embrace best practices like continuous deployment. Give it a try at &lt;a href="http://cloud.run/" target="_blank"&gt;http://cloud.run/&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/topics/google-cloud-next/developer-productivity-announcements-at-next20-onair/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;Accelerate your application development and delivery&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;At Google Cloud Next ‘20: OnAir, we released a wealth of tools and capabiltiies to enhance developer productivity.&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 17 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/application-development/cloud-run-integrates-with-continuous-deployment/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Application Development
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_App_Dev.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Now, setting up continuous deployment for Cloud Run is a snap</title>
    <description>
     You can now automatically build and deploy your code to your Cloud Run services.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_App_Dev.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/application-development/cloud-run-integrates-with-continuous-deployment/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Steren Giannini
    </name>
    <title>Product Manager</title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Setting the stage for better conversations about allyship</title>
   <link>
    https://cloud.google.com/blog/topics/inside-google-cloud/becoming-a-better-ally-to-communities-of-color/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;Jenae Butler has been a Googler for just under a year, but she became well-known both inside and outside of the company in June during a national spotlight on racial injustices here in the U.S. She created a presentation to help her colleagues understand what was going on; people found it so helpful that her “&lt;a href="https://docs.google.com/presentation/d/1ltJmjs20m1rQGXPesYRi7zLq35mgWELQO8oFOrD1UlM/edit" target="_blank"&gt;Standing United&lt;/a&gt;” resource spread quickly within Google as well as on social media. It starts with the context of George Floyd’s death and the impact police brutality has on the Black community while offering actionable tips and advice for anyone looking to learn how to be a better ally to marginalized communities of color.&lt;/p&gt;&lt;p&gt;We sat down with Jenae to hear about how she navigated her own path as a Black woman in tech, and how she advises her peers to practice allyship successfully.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tell us about your path to Google.&lt;br/&gt;&lt;/b&gt;When I was in college, internships in the technical field felt hard to obtain. It seemed like businesses were looking for a student who already had experience or other qualifications—which I found to be odd. I was a computer info systems major at Georgia State University and was looking to get into project management. I wasn't lucky enough to get an internship at the time but I found a back door into technology by working at Microsoft’s retail stores. That was my first time getting real exposure to the tech field and ended up being the reason I got into my career field.&lt;/p&gt;&lt;p&gt;I transitioned from the retail side of Microsoft through a college hire program offered by the company. I worked as a consultant focused on SQL-themed projects and eventually made my way into program management for Microsoft’s retail store support team. In that time I was heavily involved in community outreach through their Black community employee resource group (ERG) which is where my love for diversity, equity, and inclusion (DEI) stemmed from.&lt;/p&gt;&lt;p&gt;I came to Google after 5 years of working at Microsoft to join the Cloud Systems team as a program manager in Austin. My team focuses on the continued improvement and maintenance of rep-facing tools. At that time, I was a technical program manager working directly with the engineers, tasked with maintaining their workloads by lifting blockers and collaborating with the product owners for timely solution deliveries. I now work as an enablement program manager for the same team, with a new focus on training and communication mediums.&nbsp;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tell us about the creation of the Standing United deck.&lt;br/&gt;&lt;/b&gt;A common theme in my career is being one of the very few Black people and/or women on my team. The upside to this is that I’ve gotten comfortable working in these spaces that are typically white-male dominated and can normally find ways to show impact. However, I find these spaces to typically be uncomfortable when racially charged protests begin.&nbsp;&lt;/p&gt;&lt;p&gt;Having had those firsthand experiences, I knew that George Floyd’s death would spark conversations. I know how uncomfortable it can be for Black people to engage in this topic because it's complex and is a conversation that is often met with resistance or defensiveness by non-Black people. While Google has many existing resources, I wanted to find a way to aid my team with information as well as process my own thoughts and translate my own experiences as a way to equip myself. I did not realize that my work would resonate for so many Googlers around the company.&nbsp;&lt;/p&gt;&lt;p&gt;I didn't predict that the deck would make its way into so many resource hubs, team meetings, and external networks. I’ve had the opportunity to speak to thousands of people over the summer, contribute to countless DEI working sessions and events, and even join some of these work groups and resource groups as a committee lead.&lt;/p&gt;&lt;p&gt;I was afraid to do something this big, but allowing my natural instincts to guide me has had amazing results. I think we all can be shocked by what bravery produces—especially in regards to racial equity. I think it's a must for those who want to be impactful and really change outdated and incorrect narratives and the systems that are structured around them. For myself, I didn't realize that my small action would cause such a widespread impact.&nbsp;&lt;/p&gt;&lt;p&gt;I believe this same sort of effort can be repeated by everyone, honestly. Any effort—of any capacity—can create a ripple effect and inspire more folks and change than expected.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Do you have advice for others, particularly Black women in tech?&lt;br/&gt;&lt;/b&gt;Be yourself, whoever that is. You don’t have to look, act, or talk a certain way to be successful. I bring my locs, tattoos and piercings to work as a Black woman from the South every day. You may have to make sacrifices for your career, like location, but identity shouldn’t be one of them. Take time to find your community so you can have a home away from home—especially if you have to sacrifice leaving your community to pursue your career.&nbsp;&lt;/p&gt;&lt;p&gt;The Black woman's corporate experience requires so much strategy and as you try to find your place in this white-male dominated space, remember to commit to finding ways to show impact in whatever capacity you can. Your journey will be a sum of your persistence to overcome the challenges you will face, finding flexibility in your methods and staying committed to your goals.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-pull_quote"&gt;&lt;div class="uni-pull-quote h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;div class="uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3"&gt;&lt;div class="uni-pull-quote__inner-wrapper h-c-copy h-c-copy"&gt;&lt;q class="uni-pull-quote__text"&gt;Allyship can be defined as supporting those in marginalized groups to which one does not identify.&lt;/q&gt;&lt;/div&gt;&lt;/div&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-image_full_width"&gt;&lt;div class="article-module h-c-page"&gt;&lt;div class="h-c-grid"&gt;&lt;figure class="article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 "&gt;&lt;img alt="jenae butler.png" src="https://storage.googleapis.com/gweb-cloudblog-publish/images/jenae_butler.max-1000x1000.png"/&gt;&lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Thu, 17 Sep 2020 16:00:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/topics/inside-google-cloud/becoming-a-better-ally-to-communities-of-color/
   </guid>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Inside Google Cloud
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/GCP_allyship.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Setting the stage for better conversations about allyship</title>
    <description>
     Jenae Butler has navigated her path as a Black woman in tech and has tips on how to be a better ally to marginalized communities of color.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/GCP_allyship.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/topics/inside-google-cloud/becoming-a-better-ally-to-communities-of-color/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Google Cloud Blog Team 
    </name>
    <title></title>
    <department></department>
    <company></company>
   </author>
  </item>
  <item>
   <title>Export data from Cloud SQL without performance overhead</title>
   <link>
    https://cloud.google.com/blog/products/databases/introducing-cloud-sql-serverless-exports/
   </link>
   <description>
    &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="block-paragraph"&gt;&lt;div class="rich-text"&gt;&lt;p&gt;While there are a variety of reasons to export data out of your databases—such as to maintain backups, meet regulatory data retention policies, or feed downstream analytics—exports can put undue strain on your production systems, making them challenging to schedule and manage. To eliminate that resource strain, we’ve launched a new feature for &lt;a href="https://cloud.google.com/sql/"&gt;Cloud SQL&lt;/a&gt;: &lt;a href="https://cloud.google.com/sql/docs/mysql/import-export/exporting#standard-offload"&gt;serverless exports&lt;/a&gt;. Serverless exports enables you to export data from your MySQL and PostgreSQL database instances without any impact on performance or risk to your production workloads.&lt;/p&gt;&lt;p&gt;Cloud SQL &lt;a href="https://cloud.google.com/sql/docs/mysql/import-export/exporting"&gt;exports&lt;/a&gt;, which offer portable data formats (SQL, CSV), can be triggered anytime and are written to Cloud Storage buckets that you control.&lt;/p&gt;&lt;p&gt;If you need to meet regulatory requirements around data retention, you can easily send exports to buckets with &lt;a href="https://cloud.google.com/storage/docs/bucket-lock"&gt;Bucket Lock&lt;/a&gt; enabled. Bucket Lock allows you to configure a data retention policy for a Cloud Storage bucket that governs how long objects in the bucket must be retained. It also allows you to lock the data retention policy, permanently preventing the policy from being reduced or removed.&lt;/p&gt;&lt;p&gt;As another example, you can &lt;a href="https://cloud.google.com/sql/docs/mysql/import-export/exporting#exporting_data_to_a_csv_file_in"&gt;export data to CSV based on a custom query&lt;/a&gt;, then &lt;a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv"&gt;import the data&lt;/a&gt; directly to BigQuery for analytics. And if this is for regular reporting, you can schedule a recurring import with &lt;a href="https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer"&gt;Data Transfer Service&lt;/a&gt; or &lt;a href="https://cloud.google.com/solutions/scheduling-cloud-sql-database-exports-using-cloud-scheduler"&gt;Cloud Scheduler&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Using the new serverless export feature ensures these exports won’t bog down your Cloud SQL database instance, so you can continue to run predictably and reliably. And until February 2021, you can use &lt;a href="https://cloud.google.com/sql/pricing#sql-storage-networking-prices"&gt;serverless exports at no charge&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;What’s next for Cloud SQL&lt;/h3&gt;&lt;p&gt;We’re excited to see what you build with the new serverless exports feature. Have more ideas? Let us know what other features and capabilities you need with our &lt;a href="https://cloud.google.com/support/docs/issue-trackers#feature_requests"&gt;Issue Tracker&lt;/a&gt; and by joining the &lt;a href="https://groups.google.com/forum/#!forum/google-cloud-sql-discuss" target="_blank"&gt;Cloud SQL discussion group&lt;/a&gt;. We’re glad you’re along for the ride, and we look forward to your feedback!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="block-related_article_tout"&gt;&lt;div class="uni-related-article-tout h-c-page"&gt;&lt;section class="h-c-grid"&gt;&lt;a class="uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker" data-analytics='{ "event": "page interaction", "category": "article lead", "action": "related article - inline", "label": "article: {slug}" }' href="https://gweb-cloudblog-publish.appspot.com/products/databases/mysql-8-is-now-on-cloud-sql/"&gt;&lt;div class="uni-related-article-tout__inner-wrapper"&gt;&lt;p class="uni-related-article-tout__eyebrow h-c-eyebrow"&gt;Related Article&lt;/p&gt;&lt;div class="uni-related-article-tout__content-wrapper"&gt;&lt;div class="uni-related-article-tout__image-wrapper"&gt;&lt;div class="uni-related-article-tout__image" style="background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/BlogHeader_Database_3_ZIyuD1m.max-500x500.jpg')"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="uni-related-article-tout__content"&gt;&lt;h4 class="uni-related-article-tout__header h-has-bottom-margin"&gt;MySQL 8 is ready for the enterprise with Cloud SQL&lt;/h4&gt;&lt;p class="uni-related-article-tout__body"&gt;Cloud SQL, our fully managed database service for MySQL, PostgreSQL, and SQL Server, now supports MySQL 8. As a managed service, MySQL 8 ...&lt;/p&gt;&lt;div class="cta module-cta h-c-copy uni-related-article-tout__cta muted"&gt;&lt;span class="nowrap"&gt;Read Article&lt;svg class="icon h-c-icon" role="presentation"&gt;&lt;use xlink:href="#mi-arrow-forward" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
   </description>
   <pubDate>
    Wed, 16 Sep 2020 16:30:00 -0000
   </pubDate>
   <guid>
    https://cloud.google.com/blog/products/databases/introducing-cloud-sql-serverless-exports/
   </guid>
   <category>
    Data Analytics
   </category>
   <category>
    Google Cloud Platform
   </category>
   <category>
    Databases
   </category>
   <media:content url="https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Databases.max-600x600.jpg" width="540" height="540"></media:content>
   <og xmlns:og="http://ogp.me/ns#">
    <type>
     article
    </type>
    <title>Export data from Cloud SQL without performance overhead</title>
    <description>
     We’re launching export offloading in Cloud SQL so you can export data from your MySQL and PostgreSQL database instances without impacting performance or risking your production workloads.
    </description>
    <image>
     https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Databases.max-600x600.jpg
    </image>
    <site_name>
     Google
    </site_name>
    <url>
     https://cloud.google.com/blog/products/databases/introducing-cloud-sql-serverless-exports/
    </url>
   </og>
   <author xmlns:author="http://www.w3.org/2005/Atom">
    <name>
     Brett Hesterberg
    </name>
    <title>Product Manager, Google Cloud Platform</title>
    <department></department>
    <company></company>
   </author>
  </item>
 </channel>
</rss>